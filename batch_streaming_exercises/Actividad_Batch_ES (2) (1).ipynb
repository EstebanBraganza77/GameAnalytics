{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"HDFS 22\"\n",
    "COLLABORATORS = \"Borja Lopez y Esteban Braganza\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb229b3d1208c8105a34dead786cf663",
     "grade": false,
     "grade_id": "cell-69f82fe8cdafb296",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# ![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png)\n",
    "\n",
    "# Actividad BATCH\n",
    "\n",
    "## Sistema de ficheros HDFS y extracción de conocimiento de fuentes de datos heterogéneas mediante RDDs\n",
    "\n",
    "En esta práctica comenzaremos con una breve introducción a HDFS (Hadoop Distributed File System), para entender cómo se almacena y distribuye la información. Luego, nos meteremos de lleno con Spark RDDs y Spark SQL para procesar grandes volúmenes de datos de forma eficiente. Para finalizar, trabajaremos con datos relacionales y su manejo en entornos distribuidos.\n",
    "\n",
    "### Puntuación de la actividad:\n",
    "- **Ejercicio 1**: Gestión y análisis de datos en HDFS *(0.5 puntos)*\n",
    "- **Ejercicio 2**: Manipulación de RDDs en PySpark *(1.25 puntos)*\n",
    "- **Ejercicio 3**: Análisis de Datos de Tweets en PySpark *(1.25 puntos)*\n",
    "- **Ejercicio 4**: Optimización de Cálculos con Persistencia *(0.25 puntos)*\n",
    "- **Ejercicio 5**: Análisis de Tweets mediante DataFrames y consultas SQL *(2 puntos)*\n",
    "- **Ejercicio 6**: Análisis de Tweets Geolocalizados *(1.5 puntos)*\n",
    "- **Ejercicio 7**: Análisis del Patrón de Actividad Horaria en Twitter *(1 puntos)*\n",
    "- **Ejercicio 8**: Análisis de la Relación entre Tweets y Diputados por Provincia *(0.75 puntos)*\n",
    "- **Ejercicio 9**: Análisis de Interacciones de Retweets y Grados de Usuario *(0.75 puntos)*\n",
    "- **Ejercicio 10**: Distribución del Grado de Salida en una Red de Retweets *(0.75 puntos)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da7a2e8b2dbf1760efc18fdc2044ce6d",
     "grade": false,
     "grade_id": "cell-22bd70ec4e955130",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **HDFS (Hadoop Distributed File System)**\n",
    "\n",
    "<img src=\"https://hadoop.apache.org/docs/r1.2.1/images/hadoop-logo.jpg\">\n",
    "\n",
    "**HDFS (Hadoop Distributed File System)** es una parte esencial del ecosistema Big Data de Apache Hadoop. HDFS está diseñado para almacenar y gestionar grandes volúmenes de datos distribuidos en varios nodos de un cluster, proporcionando alta tolerancia a fallos y escalabilidad. En este primer ejercicio, vamos a interactuar con HDFS mediante la línea de comandos dentro del entorno de **JupyterLab**, lo que nos permitirá familiarizarnos con las operaciones básicas de este sistema de archivos distribuido.\n",
    "\n",
    "Para comenzar, es necesario abrir un terminal desde **JupyterLab**. Una vez abierto, podemos enviar comandos al sistema de archivos HDFS, que son muy similares a los comandos de bash en entornos Linux. Algunos de los comandos de HDFS que ejecutaremos comenzarán con `hdfs dfs`, seguidos de la operación que deseemos realizar. Por ejemplo, si queremos listar los archivos y directorios en el directorio raíz de HDFS, usaremos el comando ls de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9961bedbeb8070d357ae2754a5a89fc0",
     "grade": false,
     "grade_id": "cell-063a70159c8ff11f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 items\r\n",
      "drwxr-xr-x   - asolerib   supergroup          0 2020-01-16 22:12 /CFCC\r\n",
      "drwxrwxr-x   - egilbl     students            0 2024-11-11 19:10 /aula_B0.476\r\n",
      "drwxr-xr-x   - asolerib   supergroup          0 2019-10-28 11:09 /aula_B2.585\r\n",
      "drwxr-xr-x   - asolerib   supergroup          0 2019-09-25 22:10 /aula_M2.858\r\n",
      "drwxr-xr-x   - hbase      hbase               0 2024-10-22 12:25 /hbase\r\n",
      "drwxr-xr-x   - aperezgari supergroup          0 2021-08-05 12:58 /home\r\n",
      "drwxr-xr-x   - joant      supergroup          0 2023-12-10 20:28 /path\r\n",
      "drwxrwxr-x   - solr       solr                0 2019-07-23 15:49 /solr\r\n",
      "drwxrwxrwt   - hdfs       supergroup          0 2024-10-20 10:04 /tmp\r\n",
      "drwxrwxr-x   - hdfs       supergroup          0 2024-11-11 11:47 /user\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b202f1f12c635c0db089daba2aad63cf",
     "grade": false,
     "grade_id": "cell-464a41261fdc6d72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Es importante que todos los comandos se ejecuten correctamente en el entorno **JupyterLab** para obtener los resultados deseados.\n",
    "\n",
    "Para consultar la documentación completa de los comandos disponibles en HDFS, puedes acceder a la guía oficial en el siguiente enlace: [HDFS Command Guide](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html)\n",
    "\n",
    "A lo largo de este ejercicio, utilizaremos algunos de los comandos más comunes de HDFS para realizar operaciones como la creación de directorios, la carga y descarga de archivos, y la gestión de permisos, entre otros. A medida que avanzamos, te familiarizarás con la estructura de HDFS y cómo aprovechar sus funcionalidades en entornos Big Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21dc4a0099781571f670c2e3193f934b",
     "grade": false,
     "grade_id": "cell-2ae82872afbd0db8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Ejercicio 1**: Gestión y análisis de datos en HDFS (*0.5 puntos*)\n",
    "\n",
    "En este ejercicio, trabajarás con un archivo de datos de ventas llamado `ventas_globales.txt`, almacenado en la siguiente ruta `/aula_M2.858/data/ventas_globales.txt`. Tu objetivo es realizar una serie de tareas de análisis, gestión y verificación de integridad de los datos. A continuación se detallan las tareas a realizar.\n",
    "\n",
    "- Necesitas obtener información sobre el tamaño del archivo `ventas_globales.txt`, y también deberás realizar un análisis preliminar del contenido del archivo sin descargarlo completamente.\n",
    "\n",
    "- A continuación, deberás descargar una copia del archivo `ventas_globales.txt` a tu sistema local. Es importante verificar que el archivo en HDFS no presenta problemas de integridad ni bloques corruptos. Asegúrate de comprobar el estado del archivo. Una vez has verificado que el archivo esta correcto y no presenta problemas de integridad, deberás volver a subirlo dentro de la carpeta `procesado` que tienes que crear en la ruta `/user/[tu_usuario]/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File System Check\n",
    "\n",
    "\n",
    "En el siguiente código podemos apreciar el tamaño el número de bloques y el estado general del archivo en este caso el archivo se encuentra saludable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to namenode via http://eimtcld.uoc.edu:9870/fsck?ugi=ebraganza&files=1&blocks=1&path=%2Faula_M2.858%2Fdata%2Fventas_globales.txt\r\n",
      "FSCK started by ebraganza (auth:SIMPLE) from /213.73.35.119 for path /aula_M2.858/data/ventas_globales.txt at Mon Nov 11 19:44:07 CET 2024\r\n",
      "/aula_M2.858/data/ventas_globales.txt 1330 bytes, replicated: replication=3, 1 block(s):  OK\r\n",
      "0. BP-2074018746-213.73.35.119-1563889676427:blk_1224577900_150884530 len=1330 Live_repl=3\r\n",
      "\r\n",
      "\r\n",
      "Status: HEALTHY\r\n",
      " Number of data-nodes:\t3\r\n",
      " Number of racks:\t\t1\r\n",
      " Total dirs:\t\t\t0\r\n",
      " Total symlinks:\t\t0\r\n",
      "\r\n",
      "Replicated Blocks:\r\n",
      " Total size:\t1330 B\r\n",
      " Total files:\t1\r\n",
      " Total blocks (validated):\t1 (avg. block size 1330 B)\r\n",
      " Minimally replicated blocks:\t1 (100.0 %)\r\n",
      " Over-replicated blocks:\t0 (0.0 %)\r\n",
      " Under-replicated blocks:\t0 (0.0 %)\r\n",
      " Mis-replicated blocks:\t\t0 (0.0 %)\r\n",
      " Default replication factor:\t3\r\n",
      " Average block replication:\t3.0\r\n",
      " Missing blocks:\t\t0\r\n",
      " Corrupt blocks:\t\t0\r\n",
      " Missing replicas:\t\t0 (0.0 %)\r\n",
      " Blocks queued for replication:\t0\r\n",
      "\r\n",
      "Erasure Coded Block Groups:\r\n",
      " Total size:\t0 B\r\n",
      " Total files:\t0\r\n",
      " Total block groups (validated):\t0\r\n",
      " Minimally erasure-coded block groups:\t0\r\n",
      " Over-erasure-coded block groups:\t0\r\n",
      " Under-erasure-coded block groups:\t0\r\n",
      " Unsatisfactory placement block groups:\t0\r\n",
      " Average block group size:\t0.0\r\n",
      " Missing block groups:\t\t0\r\n",
      " Corrupt block groups:\t\t0\r\n",
      " Missing internal blocks:\t0\r\n",
      " Blocks queued for replication:\t0\r\n",
      "FSCK ended at Mon Nov 11 19:44:07 CET 2024 in 1 milliseconds\r\n",
      "\r\n",
      "\r\n",
      "The filesystem under path '/aula_M2.858/data/ventas_globales.txt' is HEALTHY\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs fsck /aula_M2.858/data/ventas_globales.txt -files -blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa9ad9ce3e1fce78156db6637c43a6fd",
     "grade": true,
     "grade_id": "cell-2fffed3adbc9a755",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxr-xr-x   3 mmartinmoreno supergroup       1330 2024-10-13 19:40 /aula_M2.858/data/ventas_globales.txt\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /aula_M2.858/data/ventas_globales.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspección de los datos.\n",
    "\n",
    "Observamos las 20 primeras filas del archivo que queremos analizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_Venta;Producto;Cantidad;Precio\r",
      "\r\n",
      "1;Smartphone;5;300.00\r",
      "\r\n",
      "2;Laptop;3;800.00\r",
      "\r\n",
      "3;Tablet;2;250.00\r",
      "\r\n",
      "4;Auriculares;7;50.00\r",
      "\r\n",
      "5;Reloj inteligente;1;150.00\r",
      "\r\n",
      "6;Televisor;4;600.00\r",
      "\r\n",
      "7;Cámara;8;400.00\r",
      "\r\n",
      "8;Altavoz Bluetooth;6;75.00\r",
      "\r\n",
      "9;Monitor;2;200.00\r",
      "\r\n",
      "10;Impresora;10;120.00\r",
      "\r\n",
      "11;Smartphone;4;300.00\r",
      "\r\n",
      "12;Laptop;8;800.00\r",
      "\r\n",
      "13;Tablet;6;250.00\r",
      "\r\n",
      "14;Auriculares;3;50.00\r",
      "\r\n",
      "15;Reloj inteligente;2;150.00\r",
      "\r\n",
      "16;Televisor;5;600.00\r",
      "\r\n",
      "17;Cámara;7;400.00\r",
      "\r\n",
      "18;Altavoz Bluetooth;1;75.00\r",
      "\r\n",
      "19;Monitor;3;200.00\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /aula_M2.858/data/ventas_globales.txt | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga de archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get: `ventas_globales.txt': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -get /aula_M2.858/data/ventas_globales.txt ventas_globales.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actividad_Batch_ES.ipynb  ventas_globales.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear la carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: `/user/ebraganza/procesado': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -mkdir /user/ebraganza/procesado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "drwxr-xr-x   - ebraganza ebraganza          0 2024-11-06 15:52 /user/ebraganza/procesado\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/ebraganza/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resubir Archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `/user/ebraganza/procesado/ventas_globales.txt': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -put ventas_globales.txt /user/ebraganza/procesado/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 ebraganza ebraganza       1330 2024-11-06 15:52 /user/ebraganza/procesado/ventas_globales.txt\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/ebraganza/procesado/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_Venta;Producto;Cantidad;Precio\r",
      "\r\n",
      "1;Smartphone;5;300.00\r",
      "\r\n",
      "2;Laptop;3;800.00\r",
      "\r\n",
      "3;Tablet;2;250.00\r",
      "\r\n",
      "4;Auriculares;7;50.00\r",
      "\r\n",
      "5;Reloj inteligente;1;150.00\r",
      "\r\n",
      "6;Televisor;4;600.00\r",
      "\r\n",
      "7;Cámara;8;400.00\r",
      "\r\n",
      "8;Altavoz Bluetooth;6;75.00\r",
      "\r\n",
      "9;Monitor;2;200.00\r",
      "\r\n",
      "10;Impresora;10;120.00\r",
      "\r\n",
      "11;Smartphone;4;300.00\r",
      "\r\n",
      "12;Laptop;8;800.00\r",
      "\r\n",
      "13;Tablet;6;250.00\r",
      "\r\n",
      "14;Auriculares;3;50.00\r",
      "\r\n",
      "15;Reloj inteligente;2;150.00\r",
      "\r\n",
      "16;Televisor;5;600.00\r",
      "\r\n",
      "17;Cámara;7;400.00\r",
      "\r\n",
      "18;Altavoz Bluetooth;1;75.00\r",
      "\r\n",
      "19;Monitor;3;200.00\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /user/ebraganza/procesado/ventas_globales.txt | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "766579a64bf09f05b5d872e6d6703302",
     "grade": false,
     "grade_id": "cell-808506bd1cf34534",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **Apache Spark RDDs (Resilient Distributed Datasets)**\n",
    "\n",
    "En el marco del procesamiento de grandes volúmenes de datos con Apache Spark, los RDDs, o Resilient Distributed Datasets, juegan un papel fundamental. Un RDD es una colección de elementos que se distribuyen a través de un clúster de nodos y sobre la cual se pueden aplicar operaciones que se ejecutan en paralelo.\n",
    "\n",
    "Recordemos sus características:\n",
    "\n",
    "- Inmutabilidad: Una vez que se crea un RDD, no se puede modificar. En lugar de eso, cualquier operación que modifique los datos generará un nuevo RDD.\n",
    "\n",
    "- Distribución: Los RDDs están repartidos entre los diferentes nodos del clúster, permitiendo un procesamiento paralelo eficiente.\n",
    "\n",
    "- Tolerancia a Fallos: Los RDDs son resistentes a fallos. En caso de que un nodo falle, Spark puede reconstruir los datos perdidos a partir de los datos originales y las operaciones realizadas.\n",
    "\n",
    "Esta estructura permite un procesamiento eficiente y escalable de datos, lo que es esencial para trabajar con grandes volúmenes de información en entornos de clúster.\n",
    "\n",
    "A continuación se muestra el código que debéis ejecutar para configurar vuestro entorno de Spark.\n",
    "\n",
    "> Como referencia a todos métodos que se requieren para implementar esta práctica podéis consultar:\n",
    "> * [API Python de Spark](https://archive.apache.org/dist/spark/docs/2.4.0/api/python/index.html)\n",
    "\n",
    "### Configuración del entorno python + spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a7c39355a24728f035b179efa8a2319",
     "grade": false,
     "grade_id": "cell-94e40aa6abb9fc31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f578862add8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setMaster(\"local[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0-cdh6.2.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Introducid el nombre de la app ActividadRDDs_ seguido de vuestro nombre de usuario\n",
    "conf.setAppName(\"ActividadRDDs_usuario\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea9d52ff63e42149ef1522a574ddecb9",
     "grade": false,
     "grade_id": "cell-9f46f77f8b9ce131",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Ejercicio 2**: Manipulación de RDDs en PySpark (*1.25 puntos*)\n",
    "\n",
    "En este ejercicio, te proporcionamos dos listas de números en las que realizarás diversas operaciones sobre ellas utilizando RDDs en PySpark. La solución y el enfoque quedan a tu criterio.\n",
    "Contexto:\n",
    "\n",
    "Tienes dos conjuntos de números:\n",
    "- Conjunto 1: Números del 1 al 20.\n",
    "- Conjunto 2: Números del 10 al 30.\n",
    "\n",
    "Descripción:\n",
    "\n",
    "- Debes crear RDDs a partir de estos conjuntos de números.\n",
    "\n",
    "- Tienes que transformar el primer RDD para asociar cada número con su cuadrado. Después, filtra los pares en los que el cuadrado es mayor a 50. A este RDD filtrado debes llamarlo `filtrados_rdd`.\n",
    "\n",
    "- Agrupa los datos filtrados en función de si los números originales son pares o impares. Luego, calcula la suma de los cuadrados para cada grupo. A este RDD de la suma de los cuadrados, debes llamarlo `suma_cuadrados_rdd`.\n",
    "\n",
    "- Realiza una unión e intersección entre los dos RDDs iniciales de los conjuntos de listas, deberás llamarlos `union_rdd` e `interseccion_rdd` respectivamente.\n",
    "\n",
    "- Imprime los resultados de cada una de las operaciones realizadas utilizando el método collect()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjuntos de números\n",
    "c1 = list(range(1, 21))\n",
    "c2 = list(range(10, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "# Paralelizar las listas anteriores.\n",
    "conjunto1RDD = sc.parallelize(c1)\n",
    "conjunto2RDD = sc.parallelize(c2)\n",
    "\n",
    "print(conjunto1RDD.collect())\n",
    "print(conjunto2RDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, 64), (9, 81), (10, 100), (11, 121), (12, 144), (13, 169), (14, 196), (15, 225), (16, 256), (17, 289), (18, 324), (19, 361), (20, 400)]\n"
     ]
    }
   ],
   "source": [
    "# Mapeamos cada numero a su cuadrado y filtramos para los cuadrados > 50.\n",
    "filtrados_RDD = conjunto1RDD.map(lambda x: (x, x**2)).filter(lambda x: x[1] > 50)\n",
    "print(filtrados_RDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Par', 1484), ('Impar', 1246)]\n"
     ]
    }
   ],
   "source": [
    "# Hacemos la suma de los cuadrados basados en si los numeros orignales son pares o impares.\n",
    "suma_cuadrados_rdd = (\n",
    "    filtrados_RDD\n",
    "      .map(lambda x: (\"Par\" if x[0] % 2 == 0 else 'Impar', x[1]))\n",
    "      .groupByKey()\n",
    "      .mapValues(lambda values: sum(values))\n",
    ")\n",
    "print(suma_cuadrados_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Par', 1484), ('Impar', 1246)]\n"
     ]
    }
   ],
   "source": [
    "# Otra opción utilizando la función ReduceByKeys\n",
    "suma_cuadrados_rdd = (\n",
    "    filtrados_RDD\n",
    "    .map(lambda x: (\"Par\" if x[0] % 2 == 0 else 'Impar', x[1]))\n",
    "    .reduceByKey(lambda x, y: x+y)\n",
    ")\n",
    "print(suma_cuadrados_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "564e8b1cacc0e1eac5bf9bfb9fccc6eb",
     "grade": false,
     "grade_id": "cell-314f0ca23b33a2f2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "# Union de los dos conjuntos \n",
    "union_rdd = conjunto1RDD.union(conjunto2RDD)\n",
    "print(union_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 12, 14, 16, 18, 20, 11, 13, 15, 17, 19]\n"
     ]
    }
   ],
   "source": [
    "# Interseccion de los dos conjuntos.\n",
    "intersection_rdd = conjunto1RDD.intersection(conjunto2RDD)\n",
    "print(intersection_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4819a1c09a5625d4019fa8b58248bb4c",
     "grade": true,
     "grade_id": "cell-bd7fd26bac3713f9",
     "locked": true,
     "points": 1.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "\"Solution\""
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd62f681cc9fe3c10159fe4cd080aef0",
     "grade": false,
     "grade_id": "cell-de380caf2d1be8bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Ejercicio 3**: Análisis de Datos de Tweets en PySpark (*1.25 puntos*)\n",
    "\n",
    "En este ejercicio, trabajarás con un archivo JSON llamado `tweets_sample.json` que se encuentra en la ruta `/aula_M2.858/data/tweets_sample.json`. Este archivo contiene datos de tweets y métricas relacionadas. Deberás utilizar PySpark para realizar un análisis de los datos. La estructura del archivo JSON incluye información como el número de retweets, likes, seguidores, y más. Sin embargo, para este ejercicio, te enfocarás en procesar y analizar el contenido textual de los tweets.\n",
    "\n",
    "- Carga el archivo JSON en un RDD utilizando el método `textFile()`. Examina la estructura de los datos para identificar cómo extraer el contenido relevante.\n",
    "\n",
    "- Extrae el campo tweets de cada uno de los tweets. Define y aplica una función para limpiar el texto. Esta función debe eliminar la puntuación, convertir el texto a minúsculas y asegurar que haya un solo espacio entre las palabras.\n",
    "\n",
    "- Divide el texto en palabras y filtra las palabras para quedarte con aquellas que tengan más de 3 caracteres. Después, realiza un conteo de palabras distintas que debes llamarlo `palabras_distintas_rdd`.\n",
    "\n",
    "- Por último, encuentra las 5 palabras más frecuentes que contienen la letra 'z', a este RDD debes llamarlo `top_palabras_con_z`.\n",
    "\n",
    "- Imprime los resultados de cada una de las operaciones realizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f13f8026a21d9a4fd22978e174f42d34",
     "grade": false,
     "grade_id": "cell-eaafb37f86841f7f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"tweet_id\": 1, \"user\": \"usuario1\", \"followers\": 150, \"retweets\": 5, \"likes\": 10, \"tweet\": \"¡Hola mundo! Este es un tweet de prueba para ver cómo funciona. #prueba #mundo\"}', '{\"tweet_id\": 2, \"user\": \"usuario2\", \"followers\": 300, \"retweets\": 2, \"likes\": 7, \"tweet\": \"Los datos son el nuevo petróleo. Analiza, visualiza y actúa. #data #análisis\"}', '{\"tweet_id\": 3, \"user\": \"usuario3\", \"followers\": 500, \"retweets\": 15, \"likes\": 20, \"tweet\": \"Un día productivo en la oficina. ¿Alguna vez has tenido un día así? #productividad\"}', '{\"tweet_id\": 4, \"user\": \"usuario4\", \"followers\": 250, \"retweets\": 10, \"likes\": 5, \"tweet\": \"¿Sabías que Python es uno de los lenguajes de programación más utilizados? #Python #programación\"}', '{\"tweet_id\": 5, \"user\": \"usuario5\", \"followers\": 100, \"retweets\": 1, \"likes\": 3, \"tweet\": \"La programación puede ser divertida y emocionante. ¡No te rindas! #programación\"}', '{\"tweet_id\": 6, \"user\": \"usuario6\", \"followers\": 400, \"retweets\": 0, \"likes\": 2, \"tweet\": \"Zorro: un animal ágil y rápido. #naturaleza #zorro\"}', '{\"tweet_id\": 7, \"user\": \"usuario7\", \"followers\": 600, \"retweets\": 12, \"likes\": 22, \"tweet\": \"La zona de confort es un lugar agradable, pero nada crece allí. #motivación\"}', '{\"tweet_id\": 8, \"user\": \"usuario8\", \"followers\": 50, \"retweets\": 1, \"likes\": 1, \"tweet\": \"Zambullirse en nuevas experiencias es crucial. ¡Atrévete a salir! #experiencias\"}', '{\"tweet_id\": 9, \"user\": \"usuario9\", \"followers\": 350, \"retweets\": 7, \"likes\": 15, \"tweet\": \"Zapatillas nuevas para correr. ¡Listo para la maratón! #fitness\"}', '{\"tweet_id\": 10, \"user\": \"usuario10\", \"followers\": 80, \"retweets\": 3, \"likes\": 5, \"tweet\": \"Disfrutando de un buen libro. Siempre es un placer. #lectura\"}']\n"
     ]
    }
   ],
   "source": [
    "# Creamos el RDD basados en el archivo de texto.\n",
    "tweets = sc.textFile('/aula_M2.858/data/tweets_sample.json')\n",
    "print(tweets.take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hola mundo este es un tweet de prueba para ver cómo funciona prueba mundo', 'los datos son el nuevo petróleo analiza visualiza y actúa data análisis', 'un día productivo en la oficina alguna vez has tenido un día así productividad', 'sabías que python es uno de los lenguajes de programación más utilizados python programación', 'la programación puede ser divertida y emocionante no te rindas programación', 'zorro un animal ágil y rápido naturaleza zorro', 'la zona de confort es un lugar agradable pero nada crece allí motivación', 'zambullirse en nuevas experiencias es crucial atrévete a salir experiencias', 'zapatillas nuevas para correr listo para la maratón fitness', 'disfrutando de un buen libro siempre es un placer lectura']\n"
     ]
    }
   ],
   "source": [
    "# Creamos la funcion de limpieza y la aplicamos a cada elemento del RDD\n",
    "import json\n",
    "import re\n",
    "\n",
    "def parse_tweets(tweet):\n",
    "    parsed_tweet = json.loads(tweet)\n",
    "    message = parsed_tweet['tweet']\n",
    "    message_clean = re.sub(r'[^\\w\\s]', '', message.lower()).strip()\n",
    "    message_clean = re.sub(r'\\s+', ' ', message_clean).strip()\n",
    "    return message_clean\n",
    "\n",
    "tweets = tweets.map(parse_tweets)\n",
    "\n",
    "print(tweets.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de palabras unicas en le documento es 61 \n"
     ]
    }
   ],
   "source": [
    "# Conteo de palabras unicas en general \n",
    "palabras_unicas = (\n",
    "    tweets\n",
    "        .flatMap(lambda x: x.split(' '))\n",
    "        .map(lambda palabra: (palabra, len(palabra)))\n",
    "        .filter(lambda palabra: palabra[1] > 3)\n",
    "        .keys()\n",
    "        .distinct()\n",
    "        .count()\n",
    "           )\n",
    "\n",
    "print(\"El numero de palabras unicas en le documento es {} \".format(palabras_unicas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('maratón', 1), ('crucial', 1), ('prueba', 2), ('emocionante', 1), ('ágil', 1), ('zambullirse', 1), ('correr', 1), ('productivo', 1), ('alguna', 1), ('tenido', 1), ('análisis', 1), ('allí', 1), ('datos', 1), ('naturaleza', 1), ('experiencias', 2), ('funciona', 1), ('hola', 1), ('crece', 1), ('puede', 1), ('lectura', 1), ('divertida', 1), ('pero', 1), ('fitness', 1), ('rápido', 1), ('cómo', 1), ('siempre', 1), ('tweet', 1), ('actúa', 1), ('petróleo', 1), ('data', 1), ('listo', 1), ('programación', 4), ('salir', 1), ('para', 3), ('zona', 1), ('rindas', 1), ('disfrutando', 1), ('agradable', 1), ('mundo', 2), ('atrévete', 1), ('oficina', 1), ('visualiza', 1), ('animal', 1), ('utilizados', 1), ('este', 1), ('productividad', 1), ('libro', 1), ('nuevo', 1), ('python', 2), ('lugar', 1), ('sabías', 1), ('lenguajes', 1), ('motivación', 1), ('zapatillas', 1), ('nuevas', 2), ('placer', 1), ('confort', 1), ('nada', 1), ('zorro', 2), ('buen', 1), ('analiza', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Conteo de cada palabra\n",
    "palabras_distintas_rdd = (\n",
    "    tweets\n",
    "    .flatMap(lambda x: x.split(' ')) # Separamos por palabras.\n",
    "    .map(lambda palabra: (palabra, len(palabra))) # Creamos pares de clave-valor con la palabra y su n caracteres.\n",
    "    .filter(lambda palabra: palabra[1] > 3) # Filtramos los que tienen mas de 3 caracteres.\n",
    "    .keys() # Tomamos un RDD de keys solamente.\n",
    "    .map(lambda palabra: (palabra, 1)) # Clave-valor de cada key con un 1.\n",
    "    .reduceByKey(lambda x, y: x + y) # Agregamos por cada key lo que nos da el conteo de cada palabra.\n",
    ")\n",
    "print(palabras_distintas_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('zorro', 2), ('zambullirse', 1), ('naturaleza', 1), ('zona', 1), ('visualiza', 1)]\n"
     ]
    }
   ],
   "source": [
    "top_palabras_con_z = (\n",
    "    palabras_distintas_rdd\n",
    "    .filter(lambda x: \"z\" in x[0]) # Filtramos palabras con z\n",
    "    .sortBy(lambda x: x[1], ascending=False) # Obtenemos las mas 5 frecuentes ordenando por el valor.\n",
    ")\n",
    "print(top_palabras_con_z.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "147a3fd5bd392b7593e9ddb6b7e4a830",
     "grade": true,
     "grade_id": "cell-ad5950094d75a2e5",
     "locked": true,
     "points": 1.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f7af6eeb44e66542297d1636c7cd049",
     "grade": false,
     "grade_id": "cell-cefc491088ccac0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Ejercicio 4**: Optimización de Cálculos con Persistencia (*0.25 puntos*)\n",
    "\n",
    "Para reducir los tiempos de ejecución en Spark, es fundamental utilizar la persistencia de un RDD mediante el método `persist()`. Esta técnica es particularmente útil cuando se realizan múltiples operaciones repetidas sobre un mismo RDD.\n",
    "\n",
    "Cuando persistes un RDD, Spark almacena los datos en memoria (o en disco, dependiendo del nivel de persistencia, para ver mas sobre los niveles de persistencia ir a la web [Persistencia Spark](https://archive.apache.org/dist/spark/docs/2.4.0/rdd-programming-guide.html#rdd-persistence)) para evitar recomputaciones cada vez que se necesita realizar una acción sobre el RDD. Esto significa que cada nodo del clúster guarda en su memoria las particiones del RDD que ha procesado, permitiendo que las siguientes operaciones sobre el RDD sean mucho más rápidas.\n",
    "\n",
    "**Medición de Rendimiento**\n",
    "\n",
    "Para medir la mejora en los tiempos de ejecución, podemos utilizar la función mágica `%%time` en un entorno Jupyter Notebook, que permite observar:\n",
    "\n",
    "- Wall clock time: Tiempo total real que lleva ejecutar una tarea, incluyendo la CPU, el tiempo de entrada/salida (I/O), y las posibles comunicaciones entre nodos en el clúster.\n",
    "\n",
    "- CPU time: Tiempo efectivo en que la CPU está ocupada ejecutando la tarea, excluyendo otras latencias como la de entrada/salida.\n",
    "\n",
    "En este ejercicio, se explorará el uso de la persistencia en RDDs (Resilient Distributed Datasets) utilizando PySpark. El objetivo es observar cómo la persistencia afecta al rendimiento de las operaciones de transformación y acción sobre los RDDs.\n",
    "\n",
    "- Crea un RDD a partir de una lista de números que va del 1 al 10.000.\n",
    "\n",
    "- Filtra el RDD para obtener solo los números mayores a 5.000 y almacena este resultado en un nuevo RDD.\n",
    "\n",
    "- Aplica una transformación para duplicar los valores del RDD filtrado y guárdalo en un nuevo RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88d1f94f61cf8091d75d76973b440b9a",
     "grade": true,
     "grade_id": "cell-20e79b00bce6a99d",
     "locked": false,
     "points": 0.04,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "rdd = sc.parallelize([n for n in range(1, 10001, 1)])\n",
    "rdd_filtrado = rdd.filter(lambda x: x>5000).map(lambda x: (x, x*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "556fe23ce489495050f46ccf9afceb38",
     "grade": false,
     "grade_id": "cell-3cc02595e4869b7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Utiliza el método collect() para recuperar y mostrar los números mayores a 5.000 y sus dobles, y mide el tiempo que tarda en ejecutarse esta operación utilizando la función mágica `%%time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23b72a5343db9dadc5582c54a56ceaf3",
     "grade": true,
     "grade_id": "cell-dbd8ed0fbe6cb2e3",
     "locked": false,
     "points": 0.04,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 4 ms, total: 20 ms\n",
      "Wall time: 130 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5001, 10002),\n",
       " (5002, 10004),\n",
       " (5003, 10006),\n",
       " (5004, 10008),\n",
       " (5005, 10010),\n",
       " (5006, 10012),\n",
       " (5007, 10014),\n",
       " (5008, 10016),\n",
       " (5009, 10018),\n",
       " (5010, 10020),\n",
       " (5011, 10022),\n",
       " (5012, 10024),\n",
       " (5013, 10026),\n",
       " (5014, 10028),\n",
       " (5015, 10030),\n",
       " (5016, 10032),\n",
       " (5017, 10034),\n",
       " (5018, 10036),\n",
       " (5019, 10038),\n",
       " (5020, 10040),\n",
       " (5021, 10042),\n",
       " (5022, 10044),\n",
       " (5023, 10046),\n",
       " (5024, 10048),\n",
       " (5025, 10050),\n",
       " (5026, 10052),\n",
       " (5027, 10054),\n",
       " (5028, 10056),\n",
       " (5029, 10058),\n",
       " (5030, 10060),\n",
       " (5031, 10062),\n",
       " (5032, 10064),\n",
       " (5033, 10066),\n",
       " (5034, 10068),\n",
       " (5035, 10070),\n",
       " (5036, 10072),\n",
       " (5037, 10074),\n",
       " (5038, 10076),\n",
       " (5039, 10078),\n",
       " (5040, 10080),\n",
       " (5041, 10082),\n",
       " (5042, 10084),\n",
       " (5043, 10086),\n",
       " (5044, 10088),\n",
       " (5045, 10090),\n",
       " (5046, 10092),\n",
       " (5047, 10094),\n",
       " (5048, 10096),\n",
       " (5049, 10098),\n",
       " (5050, 10100),\n",
       " (5051, 10102),\n",
       " (5052, 10104),\n",
       " (5053, 10106),\n",
       " (5054, 10108),\n",
       " (5055, 10110),\n",
       " (5056, 10112),\n",
       " (5057, 10114),\n",
       " (5058, 10116),\n",
       " (5059, 10118),\n",
       " (5060, 10120),\n",
       " (5061, 10122),\n",
       " (5062, 10124),\n",
       " (5063, 10126),\n",
       " (5064, 10128),\n",
       " (5065, 10130),\n",
       " (5066, 10132),\n",
       " (5067, 10134),\n",
       " (5068, 10136),\n",
       " (5069, 10138),\n",
       " (5070, 10140),\n",
       " (5071, 10142),\n",
       " (5072, 10144),\n",
       " (5073, 10146),\n",
       " (5074, 10148),\n",
       " (5075, 10150),\n",
       " (5076, 10152),\n",
       " (5077, 10154),\n",
       " (5078, 10156),\n",
       " (5079, 10158),\n",
       " (5080, 10160),\n",
       " (5081, 10162),\n",
       " (5082, 10164),\n",
       " (5083, 10166),\n",
       " (5084, 10168),\n",
       " (5085, 10170),\n",
       " (5086, 10172),\n",
       " (5087, 10174),\n",
       " (5088, 10176),\n",
       " (5089, 10178),\n",
       " (5090, 10180),\n",
       " (5091, 10182),\n",
       " (5092, 10184),\n",
       " (5093, 10186),\n",
       " (5094, 10188),\n",
       " (5095, 10190),\n",
       " (5096, 10192),\n",
       " (5097, 10194),\n",
       " (5098, 10196),\n",
       " (5099, 10198),\n",
       " (5100, 10200),\n",
       " (5101, 10202),\n",
       " (5102, 10204),\n",
       " (5103, 10206),\n",
       " (5104, 10208),\n",
       " (5105, 10210),\n",
       " (5106, 10212),\n",
       " (5107, 10214),\n",
       " (5108, 10216),\n",
       " (5109, 10218),\n",
       " (5110, 10220),\n",
       " (5111, 10222),\n",
       " (5112, 10224),\n",
       " (5113, 10226),\n",
       " (5114, 10228),\n",
       " (5115, 10230),\n",
       " (5116, 10232),\n",
       " (5117, 10234),\n",
       " (5118, 10236),\n",
       " (5119, 10238),\n",
       " (5120, 10240),\n",
       " (5121, 10242),\n",
       " (5122, 10244),\n",
       " (5123, 10246),\n",
       " (5124, 10248),\n",
       " (5125, 10250),\n",
       " (5126, 10252),\n",
       " (5127, 10254),\n",
       " (5128, 10256),\n",
       " (5129, 10258),\n",
       " (5130, 10260),\n",
       " (5131, 10262),\n",
       " (5132, 10264),\n",
       " (5133, 10266),\n",
       " (5134, 10268),\n",
       " (5135, 10270),\n",
       " (5136, 10272),\n",
       " (5137, 10274),\n",
       " (5138, 10276),\n",
       " (5139, 10278),\n",
       " (5140, 10280),\n",
       " (5141, 10282),\n",
       " (5142, 10284),\n",
       " (5143, 10286),\n",
       " (5144, 10288),\n",
       " (5145, 10290),\n",
       " (5146, 10292),\n",
       " (5147, 10294),\n",
       " (5148, 10296),\n",
       " (5149, 10298),\n",
       " (5150, 10300),\n",
       " (5151, 10302),\n",
       " (5152, 10304),\n",
       " (5153, 10306),\n",
       " (5154, 10308),\n",
       " (5155, 10310),\n",
       " (5156, 10312),\n",
       " (5157, 10314),\n",
       " (5158, 10316),\n",
       " (5159, 10318),\n",
       " (5160, 10320),\n",
       " (5161, 10322),\n",
       " (5162, 10324),\n",
       " (5163, 10326),\n",
       " (5164, 10328),\n",
       " (5165, 10330),\n",
       " (5166, 10332),\n",
       " (5167, 10334),\n",
       " (5168, 10336),\n",
       " (5169, 10338),\n",
       " (5170, 10340),\n",
       " (5171, 10342),\n",
       " (5172, 10344),\n",
       " (5173, 10346),\n",
       " (5174, 10348),\n",
       " (5175, 10350),\n",
       " (5176, 10352),\n",
       " (5177, 10354),\n",
       " (5178, 10356),\n",
       " (5179, 10358),\n",
       " (5180, 10360),\n",
       " (5181, 10362),\n",
       " (5182, 10364),\n",
       " (5183, 10366),\n",
       " (5184, 10368),\n",
       " (5185, 10370),\n",
       " (5186, 10372),\n",
       " (5187, 10374),\n",
       " (5188, 10376),\n",
       " (5189, 10378),\n",
       " (5190, 10380),\n",
       " (5191, 10382),\n",
       " (5192, 10384),\n",
       " (5193, 10386),\n",
       " (5194, 10388),\n",
       " (5195, 10390),\n",
       " (5196, 10392),\n",
       " (5197, 10394),\n",
       " (5198, 10396),\n",
       " (5199, 10398),\n",
       " (5200, 10400),\n",
       " (5201, 10402),\n",
       " (5202, 10404),\n",
       " (5203, 10406),\n",
       " (5204, 10408),\n",
       " (5205, 10410),\n",
       " (5206, 10412),\n",
       " (5207, 10414),\n",
       " (5208, 10416),\n",
       " (5209, 10418),\n",
       " (5210, 10420),\n",
       " (5211, 10422),\n",
       " (5212, 10424),\n",
       " (5213, 10426),\n",
       " (5214, 10428),\n",
       " (5215, 10430),\n",
       " (5216, 10432),\n",
       " (5217, 10434),\n",
       " (5218, 10436),\n",
       " (5219, 10438),\n",
       " (5220, 10440),\n",
       " (5221, 10442),\n",
       " (5222, 10444),\n",
       " (5223, 10446),\n",
       " (5224, 10448),\n",
       " (5225, 10450),\n",
       " (5226, 10452),\n",
       " (5227, 10454),\n",
       " (5228, 10456),\n",
       " (5229, 10458),\n",
       " (5230, 10460),\n",
       " (5231, 10462),\n",
       " (5232, 10464),\n",
       " (5233, 10466),\n",
       " (5234, 10468),\n",
       " (5235, 10470),\n",
       " (5236, 10472),\n",
       " (5237, 10474),\n",
       " (5238, 10476),\n",
       " (5239, 10478),\n",
       " (5240, 10480),\n",
       " (5241, 10482),\n",
       " (5242, 10484),\n",
       " (5243, 10486),\n",
       " (5244, 10488),\n",
       " (5245, 10490),\n",
       " (5246, 10492),\n",
       " (5247, 10494),\n",
       " (5248, 10496),\n",
       " (5249, 10498),\n",
       " (5250, 10500),\n",
       " (5251, 10502),\n",
       " (5252, 10504),\n",
       " (5253, 10506),\n",
       " (5254, 10508),\n",
       " (5255, 10510),\n",
       " (5256, 10512),\n",
       " (5257, 10514),\n",
       " (5258, 10516),\n",
       " (5259, 10518),\n",
       " (5260, 10520),\n",
       " (5261, 10522),\n",
       " (5262, 10524),\n",
       " (5263, 10526),\n",
       " (5264, 10528),\n",
       " (5265, 10530),\n",
       " (5266, 10532),\n",
       " (5267, 10534),\n",
       " (5268, 10536),\n",
       " (5269, 10538),\n",
       " (5270, 10540),\n",
       " (5271, 10542),\n",
       " (5272, 10544),\n",
       " (5273, 10546),\n",
       " (5274, 10548),\n",
       " (5275, 10550),\n",
       " (5276, 10552),\n",
       " (5277, 10554),\n",
       " (5278, 10556),\n",
       " (5279, 10558),\n",
       " (5280, 10560),\n",
       " (5281, 10562),\n",
       " (5282, 10564),\n",
       " (5283, 10566),\n",
       " (5284, 10568),\n",
       " (5285, 10570),\n",
       " (5286, 10572),\n",
       " (5287, 10574),\n",
       " (5288, 10576),\n",
       " (5289, 10578),\n",
       " (5290, 10580),\n",
       " (5291, 10582),\n",
       " (5292, 10584),\n",
       " (5293, 10586),\n",
       " (5294, 10588),\n",
       " (5295, 10590),\n",
       " (5296, 10592),\n",
       " (5297, 10594),\n",
       " (5298, 10596),\n",
       " (5299, 10598),\n",
       " (5300, 10600),\n",
       " (5301, 10602),\n",
       " (5302, 10604),\n",
       " (5303, 10606),\n",
       " (5304, 10608),\n",
       " (5305, 10610),\n",
       " (5306, 10612),\n",
       " (5307, 10614),\n",
       " (5308, 10616),\n",
       " (5309, 10618),\n",
       " (5310, 10620),\n",
       " (5311, 10622),\n",
       " (5312, 10624),\n",
       " (5313, 10626),\n",
       " (5314, 10628),\n",
       " (5315, 10630),\n",
       " (5316, 10632),\n",
       " (5317, 10634),\n",
       " (5318, 10636),\n",
       " (5319, 10638),\n",
       " (5320, 10640),\n",
       " (5321, 10642),\n",
       " (5322, 10644),\n",
       " (5323, 10646),\n",
       " (5324, 10648),\n",
       " (5325, 10650),\n",
       " (5326, 10652),\n",
       " (5327, 10654),\n",
       " (5328, 10656),\n",
       " (5329, 10658),\n",
       " (5330, 10660),\n",
       " (5331, 10662),\n",
       " (5332, 10664),\n",
       " (5333, 10666),\n",
       " (5334, 10668),\n",
       " (5335, 10670),\n",
       " (5336, 10672),\n",
       " (5337, 10674),\n",
       " (5338, 10676),\n",
       " (5339, 10678),\n",
       " (5340, 10680),\n",
       " (5341, 10682),\n",
       " (5342, 10684),\n",
       " (5343, 10686),\n",
       " (5344, 10688),\n",
       " (5345, 10690),\n",
       " (5346, 10692),\n",
       " (5347, 10694),\n",
       " (5348, 10696),\n",
       " (5349, 10698),\n",
       " (5350, 10700),\n",
       " (5351, 10702),\n",
       " (5352, 10704),\n",
       " (5353, 10706),\n",
       " (5354, 10708),\n",
       " (5355, 10710),\n",
       " (5356, 10712),\n",
       " (5357, 10714),\n",
       " (5358, 10716),\n",
       " (5359, 10718),\n",
       " (5360, 10720),\n",
       " (5361, 10722),\n",
       " (5362, 10724),\n",
       " (5363, 10726),\n",
       " (5364, 10728),\n",
       " (5365, 10730),\n",
       " (5366, 10732),\n",
       " (5367, 10734),\n",
       " (5368, 10736),\n",
       " (5369, 10738),\n",
       " (5370, 10740),\n",
       " (5371, 10742),\n",
       " (5372, 10744),\n",
       " (5373, 10746),\n",
       " (5374, 10748),\n",
       " (5375, 10750),\n",
       " (5376, 10752),\n",
       " (5377, 10754),\n",
       " (5378, 10756),\n",
       " (5379, 10758),\n",
       " (5380, 10760),\n",
       " (5381, 10762),\n",
       " (5382, 10764),\n",
       " (5383, 10766),\n",
       " (5384, 10768),\n",
       " (5385, 10770),\n",
       " (5386, 10772),\n",
       " (5387, 10774),\n",
       " (5388, 10776),\n",
       " (5389, 10778),\n",
       " (5390, 10780),\n",
       " (5391, 10782),\n",
       " (5392, 10784),\n",
       " (5393, 10786),\n",
       " (5394, 10788),\n",
       " (5395, 10790),\n",
       " (5396, 10792),\n",
       " (5397, 10794),\n",
       " (5398, 10796),\n",
       " (5399, 10798),\n",
       " (5400, 10800),\n",
       " (5401, 10802),\n",
       " (5402, 10804),\n",
       " (5403, 10806),\n",
       " (5404, 10808),\n",
       " (5405, 10810),\n",
       " (5406, 10812),\n",
       " (5407, 10814),\n",
       " (5408, 10816),\n",
       " (5409, 10818),\n",
       " (5410, 10820),\n",
       " (5411, 10822),\n",
       " (5412, 10824),\n",
       " (5413, 10826),\n",
       " (5414, 10828),\n",
       " (5415, 10830),\n",
       " (5416, 10832),\n",
       " (5417, 10834),\n",
       " (5418, 10836),\n",
       " (5419, 10838),\n",
       " (5420, 10840),\n",
       " (5421, 10842),\n",
       " (5422, 10844),\n",
       " (5423, 10846),\n",
       " (5424, 10848),\n",
       " (5425, 10850),\n",
       " (5426, 10852),\n",
       " (5427, 10854),\n",
       " (5428, 10856),\n",
       " (5429, 10858),\n",
       " (5430, 10860),\n",
       " (5431, 10862),\n",
       " (5432, 10864),\n",
       " (5433, 10866),\n",
       " (5434, 10868),\n",
       " (5435, 10870),\n",
       " (5436, 10872),\n",
       " (5437, 10874),\n",
       " (5438, 10876),\n",
       " (5439, 10878),\n",
       " (5440, 10880),\n",
       " (5441, 10882),\n",
       " (5442, 10884),\n",
       " (5443, 10886),\n",
       " (5444, 10888),\n",
       " (5445, 10890),\n",
       " (5446, 10892),\n",
       " (5447, 10894),\n",
       " (5448, 10896),\n",
       " (5449, 10898),\n",
       " (5450, 10900),\n",
       " (5451, 10902),\n",
       " (5452, 10904),\n",
       " (5453, 10906),\n",
       " (5454, 10908),\n",
       " (5455, 10910),\n",
       " (5456, 10912),\n",
       " (5457, 10914),\n",
       " (5458, 10916),\n",
       " (5459, 10918),\n",
       " (5460, 10920),\n",
       " (5461, 10922),\n",
       " (5462, 10924),\n",
       " (5463, 10926),\n",
       " (5464, 10928),\n",
       " (5465, 10930),\n",
       " (5466, 10932),\n",
       " (5467, 10934),\n",
       " (5468, 10936),\n",
       " (5469, 10938),\n",
       " (5470, 10940),\n",
       " (5471, 10942),\n",
       " (5472, 10944),\n",
       " (5473, 10946),\n",
       " (5474, 10948),\n",
       " (5475, 10950),\n",
       " (5476, 10952),\n",
       " (5477, 10954),\n",
       " (5478, 10956),\n",
       " (5479, 10958),\n",
       " (5480, 10960),\n",
       " (5481, 10962),\n",
       " (5482, 10964),\n",
       " (5483, 10966),\n",
       " (5484, 10968),\n",
       " (5485, 10970),\n",
       " (5486, 10972),\n",
       " (5487, 10974),\n",
       " (5488, 10976),\n",
       " (5489, 10978),\n",
       " (5490, 10980),\n",
       " (5491, 10982),\n",
       " (5492, 10984),\n",
       " (5493, 10986),\n",
       " (5494, 10988),\n",
       " (5495, 10990),\n",
       " (5496, 10992),\n",
       " (5497, 10994),\n",
       " (5498, 10996),\n",
       " (5499, 10998),\n",
       " (5500, 11000),\n",
       " (5501, 11002),\n",
       " (5502, 11004),\n",
       " (5503, 11006),\n",
       " (5504, 11008),\n",
       " (5505, 11010),\n",
       " (5506, 11012),\n",
       " (5507, 11014),\n",
       " (5508, 11016),\n",
       " (5509, 11018),\n",
       " (5510, 11020),\n",
       " (5511, 11022),\n",
       " (5512, 11024),\n",
       " (5513, 11026),\n",
       " (5514, 11028),\n",
       " (5515, 11030),\n",
       " (5516, 11032),\n",
       " (5517, 11034),\n",
       " (5518, 11036),\n",
       " (5519, 11038),\n",
       " (5520, 11040),\n",
       " (5521, 11042),\n",
       " (5522, 11044),\n",
       " (5523, 11046),\n",
       " (5524, 11048),\n",
       " (5525, 11050),\n",
       " (5526, 11052),\n",
       " (5527, 11054),\n",
       " (5528, 11056),\n",
       " (5529, 11058),\n",
       " (5530, 11060),\n",
       " (5531, 11062),\n",
       " (5532, 11064),\n",
       " (5533, 11066),\n",
       " (5534, 11068),\n",
       " (5535, 11070),\n",
       " (5536, 11072),\n",
       " (5537, 11074),\n",
       " (5538, 11076),\n",
       " (5539, 11078),\n",
       " (5540, 11080),\n",
       " (5541, 11082),\n",
       " (5542, 11084),\n",
       " (5543, 11086),\n",
       " (5544, 11088),\n",
       " (5545, 11090),\n",
       " (5546, 11092),\n",
       " (5547, 11094),\n",
       " (5548, 11096),\n",
       " (5549, 11098),\n",
       " (5550, 11100),\n",
       " (5551, 11102),\n",
       " (5552, 11104),\n",
       " (5553, 11106),\n",
       " (5554, 11108),\n",
       " (5555, 11110),\n",
       " (5556, 11112),\n",
       " (5557, 11114),\n",
       " (5558, 11116),\n",
       " (5559, 11118),\n",
       " (5560, 11120),\n",
       " (5561, 11122),\n",
       " (5562, 11124),\n",
       " (5563, 11126),\n",
       " (5564, 11128),\n",
       " (5565, 11130),\n",
       " (5566, 11132),\n",
       " (5567, 11134),\n",
       " (5568, 11136),\n",
       " (5569, 11138),\n",
       " (5570, 11140),\n",
       " (5571, 11142),\n",
       " (5572, 11144),\n",
       " (5573, 11146),\n",
       " (5574, 11148),\n",
       " (5575, 11150),\n",
       " (5576, 11152),\n",
       " (5577, 11154),\n",
       " (5578, 11156),\n",
       " (5579, 11158),\n",
       " (5580, 11160),\n",
       " (5581, 11162),\n",
       " (5582, 11164),\n",
       " (5583, 11166),\n",
       " (5584, 11168),\n",
       " (5585, 11170),\n",
       " (5586, 11172),\n",
       " (5587, 11174),\n",
       " (5588, 11176),\n",
       " (5589, 11178),\n",
       " (5590, 11180),\n",
       " (5591, 11182),\n",
       " (5592, 11184),\n",
       " (5593, 11186),\n",
       " (5594, 11188),\n",
       " (5595, 11190),\n",
       " (5596, 11192),\n",
       " (5597, 11194),\n",
       " (5598, 11196),\n",
       " (5599, 11198),\n",
       " (5600, 11200),\n",
       " (5601, 11202),\n",
       " (5602, 11204),\n",
       " (5603, 11206),\n",
       " (5604, 11208),\n",
       " (5605, 11210),\n",
       " (5606, 11212),\n",
       " (5607, 11214),\n",
       " (5608, 11216),\n",
       " (5609, 11218),\n",
       " (5610, 11220),\n",
       " (5611, 11222),\n",
       " (5612, 11224),\n",
       " (5613, 11226),\n",
       " (5614, 11228),\n",
       " (5615, 11230),\n",
       " (5616, 11232),\n",
       " (5617, 11234),\n",
       " (5618, 11236),\n",
       " (5619, 11238),\n",
       " (5620, 11240),\n",
       " (5621, 11242),\n",
       " (5622, 11244),\n",
       " (5623, 11246),\n",
       " (5624, 11248),\n",
       " (5625, 11250),\n",
       " (5626, 11252),\n",
       " (5627, 11254),\n",
       " (5628, 11256),\n",
       " (5629, 11258),\n",
       " (5630, 11260),\n",
       " (5631, 11262),\n",
       " (5632, 11264),\n",
       " (5633, 11266),\n",
       " (5634, 11268),\n",
       " (5635, 11270),\n",
       " (5636, 11272),\n",
       " (5637, 11274),\n",
       " (5638, 11276),\n",
       " (5639, 11278),\n",
       " (5640, 11280),\n",
       " (5641, 11282),\n",
       " (5642, 11284),\n",
       " (5643, 11286),\n",
       " (5644, 11288),\n",
       " (5645, 11290),\n",
       " (5646, 11292),\n",
       " (5647, 11294),\n",
       " (5648, 11296),\n",
       " (5649, 11298),\n",
       " (5650, 11300),\n",
       " (5651, 11302),\n",
       " (5652, 11304),\n",
       " (5653, 11306),\n",
       " (5654, 11308),\n",
       " (5655, 11310),\n",
       " (5656, 11312),\n",
       " (5657, 11314),\n",
       " (5658, 11316),\n",
       " (5659, 11318),\n",
       " (5660, 11320),\n",
       " (5661, 11322),\n",
       " (5662, 11324),\n",
       " (5663, 11326),\n",
       " (5664, 11328),\n",
       " (5665, 11330),\n",
       " (5666, 11332),\n",
       " (5667, 11334),\n",
       " (5668, 11336),\n",
       " (5669, 11338),\n",
       " (5670, 11340),\n",
       " (5671, 11342),\n",
       " (5672, 11344),\n",
       " (5673, 11346),\n",
       " (5674, 11348),\n",
       " (5675, 11350),\n",
       " (5676, 11352),\n",
       " (5677, 11354),\n",
       " (5678, 11356),\n",
       " (5679, 11358),\n",
       " (5680, 11360),\n",
       " (5681, 11362),\n",
       " (5682, 11364),\n",
       " (5683, 11366),\n",
       " (5684, 11368),\n",
       " (5685, 11370),\n",
       " (5686, 11372),\n",
       " (5687, 11374),\n",
       " (5688, 11376),\n",
       " (5689, 11378),\n",
       " (5690, 11380),\n",
       " (5691, 11382),\n",
       " (5692, 11384),\n",
       " (5693, 11386),\n",
       " (5694, 11388),\n",
       " (5695, 11390),\n",
       " (5696, 11392),\n",
       " (5697, 11394),\n",
       " (5698, 11396),\n",
       " (5699, 11398),\n",
       " (5700, 11400),\n",
       " (5701, 11402),\n",
       " (5702, 11404),\n",
       " (5703, 11406),\n",
       " (5704, 11408),\n",
       " (5705, 11410),\n",
       " (5706, 11412),\n",
       " (5707, 11414),\n",
       " (5708, 11416),\n",
       " (5709, 11418),\n",
       " (5710, 11420),\n",
       " (5711, 11422),\n",
       " (5712, 11424),\n",
       " (5713, 11426),\n",
       " (5714, 11428),\n",
       " (5715, 11430),\n",
       " (5716, 11432),\n",
       " (5717, 11434),\n",
       " (5718, 11436),\n",
       " (5719, 11438),\n",
       " (5720, 11440),\n",
       " (5721, 11442),\n",
       " (5722, 11444),\n",
       " (5723, 11446),\n",
       " (5724, 11448),\n",
       " (5725, 11450),\n",
       " (5726, 11452),\n",
       " (5727, 11454),\n",
       " (5728, 11456),\n",
       " (5729, 11458),\n",
       " (5730, 11460),\n",
       " (5731, 11462),\n",
       " (5732, 11464),\n",
       " (5733, 11466),\n",
       " (5734, 11468),\n",
       " (5735, 11470),\n",
       " (5736, 11472),\n",
       " (5737, 11474),\n",
       " (5738, 11476),\n",
       " (5739, 11478),\n",
       " (5740, 11480),\n",
       " (5741, 11482),\n",
       " (5742, 11484),\n",
       " (5743, 11486),\n",
       " (5744, 11488),\n",
       " (5745, 11490),\n",
       " (5746, 11492),\n",
       " (5747, 11494),\n",
       " (5748, 11496),\n",
       " (5749, 11498),\n",
       " (5750, 11500),\n",
       " (5751, 11502),\n",
       " (5752, 11504),\n",
       " (5753, 11506),\n",
       " (5754, 11508),\n",
       " (5755, 11510),\n",
       " (5756, 11512),\n",
       " (5757, 11514),\n",
       " (5758, 11516),\n",
       " (5759, 11518),\n",
       " (5760, 11520),\n",
       " (5761, 11522),\n",
       " (5762, 11524),\n",
       " (5763, 11526),\n",
       " (5764, 11528),\n",
       " (5765, 11530),\n",
       " (5766, 11532),\n",
       " (5767, 11534),\n",
       " (5768, 11536),\n",
       " (5769, 11538),\n",
       " (5770, 11540),\n",
       " (5771, 11542),\n",
       " (5772, 11544),\n",
       " (5773, 11546),\n",
       " (5774, 11548),\n",
       " (5775, 11550),\n",
       " (5776, 11552),\n",
       " (5777, 11554),\n",
       " (5778, 11556),\n",
       " (5779, 11558),\n",
       " (5780, 11560),\n",
       " (5781, 11562),\n",
       " (5782, 11564),\n",
       " (5783, 11566),\n",
       " (5784, 11568),\n",
       " (5785, 11570),\n",
       " (5786, 11572),\n",
       " (5787, 11574),\n",
       " (5788, 11576),\n",
       " (5789, 11578),\n",
       " (5790, 11580),\n",
       " (5791, 11582),\n",
       " (5792, 11584),\n",
       " (5793, 11586),\n",
       " (5794, 11588),\n",
       " (5795, 11590),\n",
       " (5796, 11592),\n",
       " (5797, 11594),\n",
       " (5798, 11596),\n",
       " (5799, 11598),\n",
       " (5800, 11600),\n",
       " (5801, 11602),\n",
       " (5802, 11604),\n",
       " (5803, 11606),\n",
       " (5804, 11608),\n",
       " (5805, 11610),\n",
       " (5806, 11612),\n",
       " (5807, 11614),\n",
       " (5808, 11616),\n",
       " (5809, 11618),\n",
       " (5810, 11620),\n",
       " (5811, 11622),\n",
       " (5812, 11624),\n",
       " (5813, 11626),\n",
       " (5814, 11628),\n",
       " (5815, 11630),\n",
       " (5816, 11632),\n",
       " (5817, 11634),\n",
       " (5818, 11636),\n",
       " (5819, 11638),\n",
       " (5820, 11640),\n",
       " (5821, 11642),\n",
       " (5822, 11644),\n",
       " (5823, 11646),\n",
       " (5824, 11648),\n",
       " (5825, 11650),\n",
       " (5826, 11652),\n",
       " (5827, 11654),\n",
       " (5828, 11656),\n",
       " (5829, 11658),\n",
       " (5830, 11660),\n",
       " (5831, 11662),\n",
       " (5832, 11664),\n",
       " (5833, 11666),\n",
       " (5834, 11668),\n",
       " (5835, 11670),\n",
       " (5836, 11672),\n",
       " (5837, 11674),\n",
       " (5838, 11676),\n",
       " (5839, 11678),\n",
       " (5840, 11680),\n",
       " (5841, 11682),\n",
       " (5842, 11684),\n",
       " (5843, 11686),\n",
       " (5844, 11688),\n",
       " (5845, 11690),\n",
       " (5846, 11692),\n",
       " (5847, 11694),\n",
       " (5848, 11696),\n",
       " (5849, 11698),\n",
       " (5850, 11700),\n",
       " (5851, 11702),\n",
       " (5852, 11704),\n",
       " (5853, 11706),\n",
       " (5854, 11708),\n",
       " (5855, 11710),\n",
       " (5856, 11712),\n",
       " (5857, 11714),\n",
       " (5858, 11716),\n",
       " (5859, 11718),\n",
       " (5860, 11720),\n",
       " (5861, 11722),\n",
       " (5862, 11724),\n",
       " (5863, 11726),\n",
       " (5864, 11728),\n",
       " (5865, 11730),\n",
       " (5866, 11732),\n",
       " (5867, 11734),\n",
       " (5868, 11736),\n",
       " (5869, 11738),\n",
       " (5870, 11740),\n",
       " (5871, 11742),\n",
       " (5872, 11744),\n",
       " (5873, 11746),\n",
       " (5874, 11748),\n",
       " (5875, 11750),\n",
       " (5876, 11752),\n",
       " (5877, 11754),\n",
       " (5878, 11756),\n",
       " (5879, 11758),\n",
       " (5880, 11760),\n",
       " (5881, 11762),\n",
       " (5882, 11764),\n",
       " (5883, 11766),\n",
       " (5884, 11768),\n",
       " (5885, 11770),\n",
       " (5886, 11772),\n",
       " (5887, 11774),\n",
       " (5888, 11776),\n",
       " (5889, 11778),\n",
       " (5890, 11780),\n",
       " (5891, 11782),\n",
       " (5892, 11784),\n",
       " (5893, 11786),\n",
       " (5894, 11788),\n",
       " (5895, 11790),\n",
       " (5896, 11792),\n",
       " (5897, 11794),\n",
       " (5898, 11796),\n",
       " (5899, 11798),\n",
       " (5900, 11800),\n",
       " (5901, 11802),\n",
       " (5902, 11804),\n",
       " (5903, 11806),\n",
       " (5904, 11808),\n",
       " (5905, 11810),\n",
       " (5906, 11812),\n",
       " (5907, 11814),\n",
       " (5908, 11816),\n",
       " (5909, 11818),\n",
       " (5910, 11820),\n",
       " (5911, 11822),\n",
       " (5912, 11824),\n",
       " (5913, 11826),\n",
       " (5914, 11828),\n",
       " (5915, 11830),\n",
       " (5916, 11832),\n",
       " (5917, 11834),\n",
       " (5918, 11836),\n",
       " (5919, 11838),\n",
       " (5920, 11840),\n",
       " (5921, 11842),\n",
       " (5922, 11844),\n",
       " (5923, 11846),\n",
       " (5924, 11848),\n",
       " (5925, 11850),\n",
       " (5926, 11852),\n",
       " (5927, 11854),\n",
       " (5928, 11856),\n",
       " (5929, 11858),\n",
       " (5930, 11860),\n",
       " (5931, 11862),\n",
       " (5932, 11864),\n",
       " (5933, 11866),\n",
       " (5934, 11868),\n",
       " (5935, 11870),\n",
       " (5936, 11872),\n",
       " (5937, 11874),\n",
       " (5938, 11876),\n",
       " (5939, 11878),\n",
       " (5940, 11880),\n",
       " (5941, 11882),\n",
       " (5942, 11884),\n",
       " (5943, 11886),\n",
       " (5944, 11888),\n",
       " (5945, 11890),\n",
       " (5946, 11892),\n",
       " (5947, 11894),\n",
       " (5948, 11896),\n",
       " (5949, 11898),\n",
       " (5950, 11900),\n",
       " (5951, 11902),\n",
       " (5952, 11904),\n",
       " (5953, 11906),\n",
       " (5954, 11908),\n",
       " (5955, 11910),\n",
       " (5956, 11912),\n",
       " (5957, 11914),\n",
       " (5958, 11916),\n",
       " (5959, 11918),\n",
       " (5960, 11920),\n",
       " (5961, 11922),\n",
       " (5962, 11924),\n",
       " (5963, 11926),\n",
       " (5964, 11928),\n",
       " (5965, 11930),\n",
       " (5966, 11932),\n",
       " (5967, 11934),\n",
       " (5968, 11936),\n",
       " (5969, 11938),\n",
       " (5970, 11940),\n",
       " (5971, 11942),\n",
       " (5972, 11944),\n",
       " (5973, 11946),\n",
       " (5974, 11948),\n",
       " (5975, 11950),\n",
       " (5976, 11952),\n",
       " (5977, 11954),\n",
       " (5978, 11956),\n",
       " (5979, 11958),\n",
       " (5980, 11960),\n",
       " (5981, 11962),\n",
       " (5982, 11964),\n",
       " (5983, 11966),\n",
       " (5984, 11968),\n",
       " (5985, 11970),\n",
       " (5986, 11972),\n",
       " (5987, 11974),\n",
       " (5988, 11976),\n",
       " (5989, 11978),\n",
       " (5990, 11980),\n",
       " (5991, 11982),\n",
       " (5992, 11984),\n",
       " (5993, 11986),\n",
       " (5994, 11988),\n",
       " (5995, 11990),\n",
       " (5996, 11992),\n",
       " (5997, 11994),\n",
       " (5998, 11996),\n",
       " (5999, 11998),\n",
       " (6000, 12000),\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rdd_filtrado.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fc6ea9f3a37e5081243aaea11a18227",
     "grade": false,
     "grade_id": "cell-d552f98ea8b2ccfc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Aplica la persistencia sobre el RDD de números mayores a 5.000 para que su contenido se mantenga en memoria entre las operaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aefdc6adb43c2eef8d0744aa4a981b66",
     "grade": true,
     "grade_id": "cell-b2f0d0dbfa3b2fc6",
     "locked": false,
     "points": 0.04,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[40] at collect at <timed eval>:1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "rdd_filtrado.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c169f04353e9d4437308fa352225c379",
     "grade": false,
     "grade_id": "cell-e317e144dfbc4476",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Vuelve a ejecutar el método collect() como antes. Compara este tiempo con el tiempo de la primera ejecución. (Puedes ejecutarlo varias veces y ver que ocurre con el tiempo de procesamiento.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "891aea65d397202a51e4e7f630fc50b2",
     "grade": true,
     "grade_id": "cell-bedf951e466e2a8f",
     "locked": false,
     "points": 0.04,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 4 ms, total: 8 ms\n",
      "Wall time: 133 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5001, 10002),\n",
       " (5002, 10004),\n",
       " (5003, 10006),\n",
       " (5004, 10008),\n",
       " (5005, 10010),\n",
       " (5006, 10012),\n",
       " (5007, 10014),\n",
       " (5008, 10016),\n",
       " (5009, 10018),\n",
       " (5010, 10020),\n",
       " (5011, 10022),\n",
       " (5012, 10024),\n",
       " (5013, 10026),\n",
       " (5014, 10028),\n",
       " (5015, 10030),\n",
       " (5016, 10032),\n",
       " (5017, 10034),\n",
       " (5018, 10036),\n",
       " (5019, 10038),\n",
       " (5020, 10040),\n",
       " (5021, 10042),\n",
       " (5022, 10044),\n",
       " (5023, 10046),\n",
       " (5024, 10048),\n",
       " (5025, 10050),\n",
       " (5026, 10052),\n",
       " (5027, 10054),\n",
       " (5028, 10056),\n",
       " (5029, 10058),\n",
       " (5030, 10060),\n",
       " (5031, 10062),\n",
       " (5032, 10064),\n",
       " (5033, 10066),\n",
       " (5034, 10068),\n",
       " (5035, 10070),\n",
       " (5036, 10072),\n",
       " (5037, 10074),\n",
       " (5038, 10076),\n",
       " (5039, 10078),\n",
       " (5040, 10080),\n",
       " (5041, 10082),\n",
       " (5042, 10084),\n",
       " (5043, 10086),\n",
       " (5044, 10088),\n",
       " (5045, 10090),\n",
       " (5046, 10092),\n",
       " (5047, 10094),\n",
       " (5048, 10096),\n",
       " (5049, 10098),\n",
       " (5050, 10100),\n",
       " (5051, 10102),\n",
       " (5052, 10104),\n",
       " (5053, 10106),\n",
       " (5054, 10108),\n",
       " (5055, 10110),\n",
       " (5056, 10112),\n",
       " (5057, 10114),\n",
       " (5058, 10116),\n",
       " (5059, 10118),\n",
       " (5060, 10120),\n",
       " (5061, 10122),\n",
       " (5062, 10124),\n",
       " (5063, 10126),\n",
       " (5064, 10128),\n",
       " (5065, 10130),\n",
       " (5066, 10132),\n",
       " (5067, 10134),\n",
       " (5068, 10136),\n",
       " (5069, 10138),\n",
       " (5070, 10140),\n",
       " (5071, 10142),\n",
       " (5072, 10144),\n",
       " (5073, 10146),\n",
       " (5074, 10148),\n",
       " (5075, 10150),\n",
       " (5076, 10152),\n",
       " (5077, 10154),\n",
       " (5078, 10156),\n",
       " (5079, 10158),\n",
       " (5080, 10160),\n",
       " (5081, 10162),\n",
       " (5082, 10164),\n",
       " (5083, 10166),\n",
       " (5084, 10168),\n",
       " (5085, 10170),\n",
       " (5086, 10172),\n",
       " (5087, 10174),\n",
       " (5088, 10176),\n",
       " (5089, 10178),\n",
       " (5090, 10180),\n",
       " (5091, 10182),\n",
       " (5092, 10184),\n",
       " (5093, 10186),\n",
       " (5094, 10188),\n",
       " (5095, 10190),\n",
       " (5096, 10192),\n",
       " (5097, 10194),\n",
       " (5098, 10196),\n",
       " (5099, 10198),\n",
       " (5100, 10200),\n",
       " (5101, 10202),\n",
       " (5102, 10204),\n",
       " (5103, 10206),\n",
       " (5104, 10208),\n",
       " (5105, 10210),\n",
       " (5106, 10212),\n",
       " (5107, 10214),\n",
       " (5108, 10216),\n",
       " (5109, 10218),\n",
       " (5110, 10220),\n",
       " (5111, 10222),\n",
       " (5112, 10224),\n",
       " (5113, 10226),\n",
       " (5114, 10228),\n",
       " (5115, 10230),\n",
       " (5116, 10232),\n",
       " (5117, 10234),\n",
       " (5118, 10236),\n",
       " (5119, 10238),\n",
       " (5120, 10240),\n",
       " (5121, 10242),\n",
       " (5122, 10244),\n",
       " (5123, 10246),\n",
       " (5124, 10248),\n",
       " (5125, 10250),\n",
       " (5126, 10252),\n",
       " (5127, 10254),\n",
       " (5128, 10256),\n",
       " (5129, 10258),\n",
       " (5130, 10260),\n",
       " (5131, 10262),\n",
       " (5132, 10264),\n",
       " (5133, 10266),\n",
       " (5134, 10268),\n",
       " (5135, 10270),\n",
       " (5136, 10272),\n",
       " (5137, 10274),\n",
       " (5138, 10276),\n",
       " (5139, 10278),\n",
       " (5140, 10280),\n",
       " (5141, 10282),\n",
       " (5142, 10284),\n",
       " (5143, 10286),\n",
       " (5144, 10288),\n",
       " (5145, 10290),\n",
       " (5146, 10292),\n",
       " (5147, 10294),\n",
       " (5148, 10296),\n",
       " (5149, 10298),\n",
       " (5150, 10300),\n",
       " (5151, 10302),\n",
       " (5152, 10304),\n",
       " (5153, 10306),\n",
       " (5154, 10308),\n",
       " (5155, 10310),\n",
       " (5156, 10312),\n",
       " (5157, 10314),\n",
       " (5158, 10316),\n",
       " (5159, 10318),\n",
       " (5160, 10320),\n",
       " (5161, 10322),\n",
       " (5162, 10324),\n",
       " (5163, 10326),\n",
       " (5164, 10328),\n",
       " (5165, 10330),\n",
       " (5166, 10332),\n",
       " (5167, 10334),\n",
       " (5168, 10336),\n",
       " (5169, 10338),\n",
       " (5170, 10340),\n",
       " (5171, 10342),\n",
       " (5172, 10344),\n",
       " (5173, 10346),\n",
       " (5174, 10348),\n",
       " (5175, 10350),\n",
       " (5176, 10352),\n",
       " (5177, 10354),\n",
       " (5178, 10356),\n",
       " (5179, 10358),\n",
       " (5180, 10360),\n",
       " (5181, 10362),\n",
       " (5182, 10364),\n",
       " (5183, 10366),\n",
       " (5184, 10368),\n",
       " (5185, 10370),\n",
       " (5186, 10372),\n",
       " (5187, 10374),\n",
       " (5188, 10376),\n",
       " (5189, 10378),\n",
       " (5190, 10380),\n",
       " (5191, 10382),\n",
       " (5192, 10384),\n",
       " (5193, 10386),\n",
       " (5194, 10388),\n",
       " (5195, 10390),\n",
       " (5196, 10392),\n",
       " (5197, 10394),\n",
       " (5198, 10396),\n",
       " (5199, 10398),\n",
       " (5200, 10400),\n",
       " (5201, 10402),\n",
       " (5202, 10404),\n",
       " (5203, 10406),\n",
       " (5204, 10408),\n",
       " (5205, 10410),\n",
       " (5206, 10412),\n",
       " (5207, 10414),\n",
       " (5208, 10416),\n",
       " (5209, 10418),\n",
       " (5210, 10420),\n",
       " (5211, 10422),\n",
       " (5212, 10424),\n",
       " (5213, 10426),\n",
       " (5214, 10428),\n",
       " (5215, 10430),\n",
       " (5216, 10432),\n",
       " (5217, 10434),\n",
       " (5218, 10436),\n",
       " (5219, 10438),\n",
       " (5220, 10440),\n",
       " (5221, 10442),\n",
       " (5222, 10444),\n",
       " (5223, 10446),\n",
       " (5224, 10448),\n",
       " (5225, 10450),\n",
       " (5226, 10452),\n",
       " (5227, 10454),\n",
       " (5228, 10456),\n",
       " (5229, 10458),\n",
       " (5230, 10460),\n",
       " (5231, 10462),\n",
       " (5232, 10464),\n",
       " (5233, 10466),\n",
       " (5234, 10468),\n",
       " (5235, 10470),\n",
       " (5236, 10472),\n",
       " (5237, 10474),\n",
       " (5238, 10476),\n",
       " (5239, 10478),\n",
       " (5240, 10480),\n",
       " (5241, 10482),\n",
       " (5242, 10484),\n",
       " (5243, 10486),\n",
       " (5244, 10488),\n",
       " (5245, 10490),\n",
       " (5246, 10492),\n",
       " (5247, 10494),\n",
       " (5248, 10496),\n",
       " (5249, 10498),\n",
       " (5250, 10500),\n",
       " (5251, 10502),\n",
       " (5252, 10504),\n",
       " (5253, 10506),\n",
       " (5254, 10508),\n",
       " (5255, 10510),\n",
       " (5256, 10512),\n",
       " (5257, 10514),\n",
       " (5258, 10516),\n",
       " (5259, 10518),\n",
       " (5260, 10520),\n",
       " (5261, 10522),\n",
       " (5262, 10524),\n",
       " (5263, 10526),\n",
       " (5264, 10528),\n",
       " (5265, 10530),\n",
       " (5266, 10532),\n",
       " (5267, 10534),\n",
       " (5268, 10536),\n",
       " (5269, 10538),\n",
       " (5270, 10540),\n",
       " (5271, 10542),\n",
       " (5272, 10544),\n",
       " (5273, 10546),\n",
       " (5274, 10548),\n",
       " (5275, 10550),\n",
       " (5276, 10552),\n",
       " (5277, 10554),\n",
       " (5278, 10556),\n",
       " (5279, 10558),\n",
       " (5280, 10560),\n",
       " (5281, 10562),\n",
       " (5282, 10564),\n",
       " (5283, 10566),\n",
       " (5284, 10568),\n",
       " (5285, 10570),\n",
       " (5286, 10572),\n",
       " (5287, 10574),\n",
       " (5288, 10576),\n",
       " (5289, 10578),\n",
       " (5290, 10580),\n",
       " (5291, 10582),\n",
       " (5292, 10584),\n",
       " (5293, 10586),\n",
       " (5294, 10588),\n",
       " (5295, 10590),\n",
       " (5296, 10592),\n",
       " (5297, 10594),\n",
       " (5298, 10596),\n",
       " (5299, 10598),\n",
       " (5300, 10600),\n",
       " (5301, 10602),\n",
       " (5302, 10604),\n",
       " (5303, 10606),\n",
       " (5304, 10608),\n",
       " (5305, 10610),\n",
       " (5306, 10612),\n",
       " (5307, 10614),\n",
       " (5308, 10616),\n",
       " (5309, 10618),\n",
       " (5310, 10620),\n",
       " (5311, 10622),\n",
       " (5312, 10624),\n",
       " (5313, 10626),\n",
       " (5314, 10628),\n",
       " (5315, 10630),\n",
       " (5316, 10632),\n",
       " (5317, 10634),\n",
       " (5318, 10636),\n",
       " (5319, 10638),\n",
       " (5320, 10640),\n",
       " (5321, 10642),\n",
       " (5322, 10644),\n",
       " (5323, 10646),\n",
       " (5324, 10648),\n",
       " (5325, 10650),\n",
       " (5326, 10652),\n",
       " (5327, 10654),\n",
       " (5328, 10656),\n",
       " (5329, 10658),\n",
       " (5330, 10660),\n",
       " (5331, 10662),\n",
       " (5332, 10664),\n",
       " (5333, 10666),\n",
       " (5334, 10668),\n",
       " (5335, 10670),\n",
       " (5336, 10672),\n",
       " (5337, 10674),\n",
       " (5338, 10676),\n",
       " (5339, 10678),\n",
       " (5340, 10680),\n",
       " (5341, 10682),\n",
       " (5342, 10684),\n",
       " (5343, 10686),\n",
       " (5344, 10688),\n",
       " (5345, 10690),\n",
       " (5346, 10692),\n",
       " (5347, 10694),\n",
       " (5348, 10696),\n",
       " (5349, 10698),\n",
       " (5350, 10700),\n",
       " (5351, 10702),\n",
       " (5352, 10704),\n",
       " (5353, 10706),\n",
       " (5354, 10708),\n",
       " (5355, 10710),\n",
       " (5356, 10712),\n",
       " (5357, 10714),\n",
       " (5358, 10716),\n",
       " (5359, 10718),\n",
       " (5360, 10720),\n",
       " (5361, 10722),\n",
       " (5362, 10724),\n",
       " (5363, 10726),\n",
       " (5364, 10728),\n",
       " (5365, 10730),\n",
       " (5366, 10732),\n",
       " (5367, 10734),\n",
       " (5368, 10736),\n",
       " (5369, 10738),\n",
       " (5370, 10740),\n",
       " (5371, 10742),\n",
       " (5372, 10744),\n",
       " (5373, 10746),\n",
       " (5374, 10748),\n",
       " (5375, 10750),\n",
       " (5376, 10752),\n",
       " (5377, 10754),\n",
       " (5378, 10756),\n",
       " (5379, 10758),\n",
       " (5380, 10760),\n",
       " (5381, 10762),\n",
       " (5382, 10764),\n",
       " (5383, 10766),\n",
       " (5384, 10768),\n",
       " (5385, 10770),\n",
       " (5386, 10772),\n",
       " (5387, 10774),\n",
       " (5388, 10776),\n",
       " (5389, 10778),\n",
       " (5390, 10780),\n",
       " (5391, 10782),\n",
       " (5392, 10784),\n",
       " (5393, 10786),\n",
       " (5394, 10788),\n",
       " (5395, 10790),\n",
       " (5396, 10792),\n",
       " (5397, 10794),\n",
       " (5398, 10796),\n",
       " (5399, 10798),\n",
       " (5400, 10800),\n",
       " (5401, 10802),\n",
       " (5402, 10804),\n",
       " (5403, 10806),\n",
       " (5404, 10808),\n",
       " (5405, 10810),\n",
       " (5406, 10812),\n",
       " (5407, 10814),\n",
       " (5408, 10816),\n",
       " (5409, 10818),\n",
       " (5410, 10820),\n",
       " (5411, 10822),\n",
       " (5412, 10824),\n",
       " (5413, 10826),\n",
       " (5414, 10828),\n",
       " (5415, 10830),\n",
       " (5416, 10832),\n",
       " (5417, 10834),\n",
       " (5418, 10836),\n",
       " (5419, 10838),\n",
       " (5420, 10840),\n",
       " (5421, 10842),\n",
       " (5422, 10844),\n",
       " (5423, 10846),\n",
       " (5424, 10848),\n",
       " (5425, 10850),\n",
       " (5426, 10852),\n",
       " (5427, 10854),\n",
       " (5428, 10856),\n",
       " (5429, 10858),\n",
       " (5430, 10860),\n",
       " (5431, 10862),\n",
       " (5432, 10864),\n",
       " (5433, 10866),\n",
       " (5434, 10868),\n",
       " (5435, 10870),\n",
       " (5436, 10872),\n",
       " (5437, 10874),\n",
       " (5438, 10876),\n",
       " (5439, 10878),\n",
       " (5440, 10880),\n",
       " (5441, 10882),\n",
       " (5442, 10884),\n",
       " (5443, 10886),\n",
       " (5444, 10888),\n",
       " (5445, 10890),\n",
       " (5446, 10892),\n",
       " (5447, 10894),\n",
       " (5448, 10896),\n",
       " (5449, 10898),\n",
       " (5450, 10900),\n",
       " (5451, 10902),\n",
       " (5452, 10904),\n",
       " (5453, 10906),\n",
       " (5454, 10908),\n",
       " (5455, 10910),\n",
       " (5456, 10912),\n",
       " (5457, 10914),\n",
       " (5458, 10916),\n",
       " (5459, 10918),\n",
       " (5460, 10920),\n",
       " (5461, 10922),\n",
       " (5462, 10924),\n",
       " (5463, 10926),\n",
       " (5464, 10928),\n",
       " (5465, 10930),\n",
       " (5466, 10932),\n",
       " (5467, 10934),\n",
       " (5468, 10936),\n",
       " (5469, 10938),\n",
       " (5470, 10940),\n",
       " (5471, 10942),\n",
       " (5472, 10944),\n",
       " (5473, 10946),\n",
       " (5474, 10948),\n",
       " (5475, 10950),\n",
       " (5476, 10952),\n",
       " (5477, 10954),\n",
       " (5478, 10956),\n",
       " (5479, 10958),\n",
       " (5480, 10960),\n",
       " (5481, 10962),\n",
       " (5482, 10964),\n",
       " (5483, 10966),\n",
       " (5484, 10968),\n",
       " (5485, 10970),\n",
       " (5486, 10972),\n",
       " (5487, 10974),\n",
       " (5488, 10976),\n",
       " (5489, 10978),\n",
       " (5490, 10980),\n",
       " (5491, 10982),\n",
       " (5492, 10984),\n",
       " (5493, 10986),\n",
       " (5494, 10988),\n",
       " (5495, 10990),\n",
       " (5496, 10992),\n",
       " (5497, 10994),\n",
       " (5498, 10996),\n",
       " (5499, 10998),\n",
       " (5500, 11000),\n",
       " (5501, 11002),\n",
       " (5502, 11004),\n",
       " (5503, 11006),\n",
       " (5504, 11008),\n",
       " (5505, 11010),\n",
       " (5506, 11012),\n",
       " (5507, 11014),\n",
       " (5508, 11016),\n",
       " (5509, 11018),\n",
       " (5510, 11020),\n",
       " (5511, 11022),\n",
       " (5512, 11024),\n",
       " (5513, 11026),\n",
       " (5514, 11028),\n",
       " (5515, 11030),\n",
       " (5516, 11032),\n",
       " (5517, 11034),\n",
       " (5518, 11036),\n",
       " (5519, 11038),\n",
       " (5520, 11040),\n",
       " (5521, 11042),\n",
       " (5522, 11044),\n",
       " (5523, 11046),\n",
       " (5524, 11048),\n",
       " (5525, 11050),\n",
       " (5526, 11052),\n",
       " (5527, 11054),\n",
       " (5528, 11056),\n",
       " (5529, 11058),\n",
       " (5530, 11060),\n",
       " (5531, 11062),\n",
       " (5532, 11064),\n",
       " (5533, 11066),\n",
       " (5534, 11068),\n",
       " (5535, 11070),\n",
       " (5536, 11072),\n",
       " (5537, 11074),\n",
       " (5538, 11076),\n",
       " (5539, 11078),\n",
       " (5540, 11080),\n",
       " (5541, 11082),\n",
       " (5542, 11084),\n",
       " (5543, 11086),\n",
       " (5544, 11088),\n",
       " (5545, 11090),\n",
       " (5546, 11092),\n",
       " (5547, 11094),\n",
       " (5548, 11096),\n",
       " (5549, 11098),\n",
       " (5550, 11100),\n",
       " (5551, 11102),\n",
       " (5552, 11104),\n",
       " (5553, 11106),\n",
       " (5554, 11108),\n",
       " (5555, 11110),\n",
       " (5556, 11112),\n",
       " (5557, 11114),\n",
       " (5558, 11116),\n",
       " (5559, 11118),\n",
       " (5560, 11120),\n",
       " (5561, 11122),\n",
       " (5562, 11124),\n",
       " (5563, 11126),\n",
       " (5564, 11128),\n",
       " (5565, 11130),\n",
       " (5566, 11132),\n",
       " (5567, 11134),\n",
       " (5568, 11136),\n",
       " (5569, 11138),\n",
       " (5570, 11140),\n",
       " (5571, 11142),\n",
       " (5572, 11144),\n",
       " (5573, 11146),\n",
       " (5574, 11148),\n",
       " (5575, 11150),\n",
       " (5576, 11152),\n",
       " (5577, 11154),\n",
       " (5578, 11156),\n",
       " (5579, 11158),\n",
       " (5580, 11160),\n",
       " (5581, 11162),\n",
       " (5582, 11164),\n",
       " (5583, 11166),\n",
       " (5584, 11168),\n",
       " (5585, 11170),\n",
       " (5586, 11172),\n",
       " (5587, 11174),\n",
       " (5588, 11176),\n",
       " (5589, 11178),\n",
       " (5590, 11180),\n",
       " (5591, 11182),\n",
       " (5592, 11184),\n",
       " (5593, 11186),\n",
       " (5594, 11188),\n",
       " (5595, 11190),\n",
       " (5596, 11192),\n",
       " (5597, 11194),\n",
       " (5598, 11196),\n",
       " (5599, 11198),\n",
       " (5600, 11200),\n",
       " (5601, 11202),\n",
       " (5602, 11204),\n",
       " (5603, 11206),\n",
       " (5604, 11208),\n",
       " (5605, 11210),\n",
       " (5606, 11212),\n",
       " (5607, 11214),\n",
       " (5608, 11216),\n",
       " (5609, 11218),\n",
       " (5610, 11220),\n",
       " (5611, 11222),\n",
       " (5612, 11224),\n",
       " (5613, 11226),\n",
       " (5614, 11228),\n",
       " (5615, 11230),\n",
       " (5616, 11232),\n",
       " (5617, 11234),\n",
       " (5618, 11236),\n",
       " (5619, 11238),\n",
       " (5620, 11240),\n",
       " (5621, 11242),\n",
       " (5622, 11244),\n",
       " (5623, 11246),\n",
       " (5624, 11248),\n",
       " (5625, 11250),\n",
       " (5626, 11252),\n",
       " (5627, 11254),\n",
       " (5628, 11256),\n",
       " (5629, 11258),\n",
       " (5630, 11260),\n",
       " (5631, 11262),\n",
       " (5632, 11264),\n",
       " (5633, 11266),\n",
       " (5634, 11268),\n",
       " (5635, 11270),\n",
       " (5636, 11272),\n",
       " (5637, 11274),\n",
       " (5638, 11276),\n",
       " (5639, 11278),\n",
       " (5640, 11280),\n",
       " (5641, 11282),\n",
       " (5642, 11284),\n",
       " (5643, 11286),\n",
       " (5644, 11288),\n",
       " (5645, 11290),\n",
       " (5646, 11292),\n",
       " (5647, 11294),\n",
       " (5648, 11296),\n",
       " (5649, 11298),\n",
       " (5650, 11300),\n",
       " (5651, 11302),\n",
       " (5652, 11304),\n",
       " (5653, 11306),\n",
       " (5654, 11308),\n",
       " (5655, 11310),\n",
       " (5656, 11312),\n",
       " (5657, 11314),\n",
       " (5658, 11316),\n",
       " (5659, 11318),\n",
       " (5660, 11320),\n",
       " (5661, 11322),\n",
       " (5662, 11324),\n",
       " (5663, 11326),\n",
       " (5664, 11328),\n",
       " (5665, 11330),\n",
       " (5666, 11332),\n",
       " (5667, 11334),\n",
       " (5668, 11336),\n",
       " (5669, 11338),\n",
       " (5670, 11340),\n",
       " (5671, 11342),\n",
       " (5672, 11344),\n",
       " (5673, 11346),\n",
       " (5674, 11348),\n",
       " (5675, 11350),\n",
       " (5676, 11352),\n",
       " (5677, 11354),\n",
       " (5678, 11356),\n",
       " (5679, 11358),\n",
       " (5680, 11360),\n",
       " (5681, 11362),\n",
       " (5682, 11364),\n",
       " (5683, 11366),\n",
       " (5684, 11368),\n",
       " (5685, 11370),\n",
       " (5686, 11372),\n",
       " (5687, 11374),\n",
       " (5688, 11376),\n",
       " (5689, 11378),\n",
       " (5690, 11380),\n",
       " (5691, 11382),\n",
       " (5692, 11384),\n",
       " (5693, 11386),\n",
       " (5694, 11388),\n",
       " (5695, 11390),\n",
       " (5696, 11392),\n",
       " (5697, 11394),\n",
       " (5698, 11396),\n",
       " (5699, 11398),\n",
       " (5700, 11400),\n",
       " (5701, 11402),\n",
       " (5702, 11404),\n",
       " (5703, 11406),\n",
       " (5704, 11408),\n",
       " (5705, 11410),\n",
       " (5706, 11412),\n",
       " (5707, 11414),\n",
       " (5708, 11416),\n",
       " (5709, 11418),\n",
       " (5710, 11420),\n",
       " (5711, 11422),\n",
       " (5712, 11424),\n",
       " (5713, 11426),\n",
       " (5714, 11428),\n",
       " (5715, 11430),\n",
       " (5716, 11432),\n",
       " (5717, 11434),\n",
       " (5718, 11436),\n",
       " (5719, 11438),\n",
       " (5720, 11440),\n",
       " (5721, 11442),\n",
       " (5722, 11444),\n",
       " (5723, 11446),\n",
       " (5724, 11448),\n",
       " (5725, 11450),\n",
       " (5726, 11452),\n",
       " (5727, 11454),\n",
       " (5728, 11456),\n",
       " (5729, 11458),\n",
       " (5730, 11460),\n",
       " (5731, 11462),\n",
       " (5732, 11464),\n",
       " (5733, 11466),\n",
       " (5734, 11468),\n",
       " (5735, 11470),\n",
       " (5736, 11472),\n",
       " (5737, 11474),\n",
       " (5738, 11476),\n",
       " (5739, 11478),\n",
       " (5740, 11480),\n",
       " (5741, 11482),\n",
       " (5742, 11484),\n",
       " (5743, 11486),\n",
       " (5744, 11488),\n",
       " (5745, 11490),\n",
       " (5746, 11492),\n",
       " (5747, 11494),\n",
       " (5748, 11496),\n",
       " (5749, 11498),\n",
       " (5750, 11500),\n",
       " (5751, 11502),\n",
       " (5752, 11504),\n",
       " (5753, 11506),\n",
       " (5754, 11508),\n",
       " (5755, 11510),\n",
       " (5756, 11512),\n",
       " (5757, 11514),\n",
       " (5758, 11516),\n",
       " (5759, 11518),\n",
       " (5760, 11520),\n",
       " (5761, 11522),\n",
       " (5762, 11524),\n",
       " (5763, 11526),\n",
       " (5764, 11528),\n",
       " (5765, 11530),\n",
       " (5766, 11532),\n",
       " (5767, 11534),\n",
       " (5768, 11536),\n",
       " (5769, 11538),\n",
       " (5770, 11540),\n",
       " (5771, 11542),\n",
       " (5772, 11544),\n",
       " (5773, 11546),\n",
       " (5774, 11548),\n",
       " (5775, 11550),\n",
       " (5776, 11552),\n",
       " (5777, 11554),\n",
       " (5778, 11556),\n",
       " (5779, 11558),\n",
       " (5780, 11560),\n",
       " (5781, 11562),\n",
       " (5782, 11564),\n",
       " (5783, 11566),\n",
       " (5784, 11568),\n",
       " (5785, 11570),\n",
       " (5786, 11572),\n",
       " (5787, 11574),\n",
       " (5788, 11576),\n",
       " (5789, 11578),\n",
       " (5790, 11580),\n",
       " (5791, 11582),\n",
       " (5792, 11584),\n",
       " (5793, 11586),\n",
       " (5794, 11588),\n",
       " (5795, 11590),\n",
       " (5796, 11592),\n",
       " (5797, 11594),\n",
       " (5798, 11596),\n",
       " (5799, 11598),\n",
       " (5800, 11600),\n",
       " (5801, 11602),\n",
       " (5802, 11604),\n",
       " (5803, 11606),\n",
       " (5804, 11608),\n",
       " (5805, 11610),\n",
       " (5806, 11612),\n",
       " (5807, 11614),\n",
       " (5808, 11616),\n",
       " (5809, 11618),\n",
       " (5810, 11620),\n",
       " (5811, 11622),\n",
       " (5812, 11624),\n",
       " (5813, 11626),\n",
       " (5814, 11628),\n",
       " (5815, 11630),\n",
       " (5816, 11632),\n",
       " (5817, 11634),\n",
       " (5818, 11636),\n",
       " (5819, 11638),\n",
       " (5820, 11640),\n",
       " (5821, 11642),\n",
       " (5822, 11644),\n",
       " (5823, 11646),\n",
       " (5824, 11648),\n",
       " (5825, 11650),\n",
       " (5826, 11652),\n",
       " (5827, 11654),\n",
       " (5828, 11656),\n",
       " (5829, 11658),\n",
       " (5830, 11660),\n",
       " (5831, 11662),\n",
       " (5832, 11664),\n",
       " (5833, 11666),\n",
       " (5834, 11668),\n",
       " (5835, 11670),\n",
       " (5836, 11672),\n",
       " (5837, 11674),\n",
       " (5838, 11676),\n",
       " (5839, 11678),\n",
       " (5840, 11680),\n",
       " (5841, 11682),\n",
       " (5842, 11684),\n",
       " (5843, 11686),\n",
       " (5844, 11688),\n",
       " (5845, 11690),\n",
       " (5846, 11692),\n",
       " (5847, 11694),\n",
       " (5848, 11696),\n",
       " (5849, 11698),\n",
       " (5850, 11700),\n",
       " (5851, 11702),\n",
       " (5852, 11704),\n",
       " (5853, 11706),\n",
       " (5854, 11708),\n",
       " (5855, 11710),\n",
       " (5856, 11712),\n",
       " (5857, 11714),\n",
       " (5858, 11716),\n",
       " (5859, 11718),\n",
       " (5860, 11720),\n",
       " (5861, 11722),\n",
       " (5862, 11724),\n",
       " (5863, 11726),\n",
       " (5864, 11728),\n",
       " (5865, 11730),\n",
       " (5866, 11732),\n",
       " (5867, 11734),\n",
       " (5868, 11736),\n",
       " (5869, 11738),\n",
       " (5870, 11740),\n",
       " (5871, 11742),\n",
       " (5872, 11744),\n",
       " (5873, 11746),\n",
       " (5874, 11748),\n",
       " (5875, 11750),\n",
       " (5876, 11752),\n",
       " (5877, 11754),\n",
       " (5878, 11756),\n",
       " (5879, 11758),\n",
       " (5880, 11760),\n",
       " (5881, 11762),\n",
       " (5882, 11764),\n",
       " (5883, 11766),\n",
       " (5884, 11768),\n",
       " (5885, 11770),\n",
       " (5886, 11772),\n",
       " (5887, 11774),\n",
       " (5888, 11776),\n",
       " (5889, 11778),\n",
       " (5890, 11780),\n",
       " (5891, 11782),\n",
       " (5892, 11784),\n",
       " (5893, 11786),\n",
       " (5894, 11788),\n",
       " (5895, 11790),\n",
       " (5896, 11792),\n",
       " (5897, 11794),\n",
       " (5898, 11796),\n",
       " (5899, 11798),\n",
       " (5900, 11800),\n",
       " (5901, 11802),\n",
       " (5902, 11804),\n",
       " (5903, 11806),\n",
       " (5904, 11808),\n",
       " (5905, 11810),\n",
       " (5906, 11812),\n",
       " (5907, 11814),\n",
       " (5908, 11816),\n",
       " (5909, 11818),\n",
       " (5910, 11820),\n",
       " (5911, 11822),\n",
       " (5912, 11824),\n",
       " (5913, 11826),\n",
       " (5914, 11828),\n",
       " (5915, 11830),\n",
       " (5916, 11832),\n",
       " (5917, 11834),\n",
       " (5918, 11836),\n",
       " (5919, 11838),\n",
       " (5920, 11840),\n",
       " (5921, 11842),\n",
       " (5922, 11844),\n",
       " (5923, 11846),\n",
       " (5924, 11848),\n",
       " (5925, 11850),\n",
       " (5926, 11852),\n",
       " (5927, 11854),\n",
       " (5928, 11856),\n",
       " (5929, 11858),\n",
       " (5930, 11860),\n",
       " (5931, 11862),\n",
       " (5932, 11864),\n",
       " (5933, 11866),\n",
       " (5934, 11868),\n",
       " (5935, 11870),\n",
       " (5936, 11872),\n",
       " (5937, 11874),\n",
       " (5938, 11876),\n",
       " (5939, 11878),\n",
       " (5940, 11880),\n",
       " (5941, 11882),\n",
       " (5942, 11884),\n",
       " (5943, 11886),\n",
       " (5944, 11888),\n",
       " (5945, 11890),\n",
       " (5946, 11892),\n",
       " (5947, 11894),\n",
       " (5948, 11896),\n",
       " (5949, 11898),\n",
       " (5950, 11900),\n",
       " (5951, 11902),\n",
       " (5952, 11904),\n",
       " (5953, 11906),\n",
       " (5954, 11908),\n",
       " (5955, 11910),\n",
       " (5956, 11912),\n",
       " (5957, 11914),\n",
       " (5958, 11916),\n",
       " (5959, 11918),\n",
       " (5960, 11920),\n",
       " (5961, 11922),\n",
       " (5962, 11924),\n",
       " (5963, 11926),\n",
       " (5964, 11928),\n",
       " (5965, 11930),\n",
       " (5966, 11932),\n",
       " (5967, 11934),\n",
       " (5968, 11936),\n",
       " (5969, 11938),\n",
       " (5970, 11940),\n",
       " (5971, 11942),\n",
       " (5972, 11944),\n",
       " (5973, 11946),\n",
       " (5974, 11948),\n",
       " (5975, 11950),\n",
       " (5976, 11952),\n",
       " (5977, 11954),\n",
       " (5978, 11956),\n",
       " (5979, 11958),\n",
       " (5980, 11960),\n",
       " (5981, 11962),\n",
       " (5982, 11964),\n",
       " (5983, 11966),\n",
       " (5984, 11968),\n",
       " (5985, 11970),\n",
       " (5986, 11972),\n",
       " (5987, 11974),\n",
       " (5988, 11976),\n",
       " (5989, 11978),\n",
       " (5990, 11980),\n",
       " (5991, 11982),\n",
       " (5992, 11984),\n",
       " (5993, 11986),\n",
       " (5994, 11988),\n",
       " (5995, 11990),\n",
       " (5996, 11992),\n",
       " (5997, 11994),\n",
       " (5998, 11996),\n",
       " (5999, 11998),\n",
       " (6000, 12000),\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rdd_filtrado.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12353a28dca852b1092a3685bc9d36bb",
     "grade": false,
     "grade_id": "cell-6d7fc7daa908a284",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Deshazte de la persistencia del RDD utilizando unpersist() para liberar recursos y detén la sesión de Spark al final del ejercicio con sc.stop()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f59a0df333b77f9a1b5ae6d14d6ff7d5",
     "grade": true,
     "grade_id": "cell-758588781a39fc7c",
     "locked": false,
     "points": 0.04,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[40] at collect at <timed eval>:1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_filtrado.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16d2f2d1a0187198e0fe1fe0b56833ab",
     "grade": false,
     "grade_id": "cell-a26ae2c6d94330f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Al terminar el ejercicio, analiza y comenta los resultados obtenidos, explicando cómo la persistencia afectó el rendimiento de tus cálculos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ha mencionado en la informacion proporcionada. Persist nos permite mantener un RDD guardado en memoria, de manera que no tenga que recalcularse otra vez. Podemos calaramente ver que para este caso que una ves hemos usado persist el tiempo que toma el collect es menor al que teniamos antes de realizar el persist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0dbed1299cf2ee33d9803541c0a82438",
     "grade": true,
     "grade_id": "cell-8c4867c600d1589a",
     "locked": false,
     "points": 0.05,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c14c79880f5327568ba311ece1a0c818",
     "grade": false,
     "grade_id": "cell-8be99cc6aa71a595",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **Apache Spark Dataframes**\n",
    "\n",
    "En esta parte de la práctica vamos a introducir los elementos que ofrece Spark para trabajar con estructuras de datos. Veremos desde estructuras muy simples hasta estructuras complejas, donde los campos pueden a su vez tener campos anidados. En concreto utilizaremos datos de Twitter capturados en el contexto de las elecciones generales en España del 28 de abril de 2019\n",
    "\n",
    "### Configuración del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a701a660c946c6183d1ab080a4beeab8",
     "grade": false,
     "grade_id": "cell-1c9b92951b2b66ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a63019694978ebeccd777c939176501",
     "grade": false,
     "grade_id": "cell-fdb813eb32e1d141",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from math import floor\n",
    "from pyspark import SparkConf, SparkContext, SQLContext, HiveContext\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMIT_ARGS = \"--jars /opt/cloudera/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373/jars/graphframes_graphframes-0.7.0-spark2.4-s_2.11.jar pyspark-shell\"\n",
    "\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = SUBMIT_ARGS\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setMaster(\"local[1]\")\n",
    "# Introducid el nombre de la app ActividadSparkSQL_ seguido de vuestro nombre de usuario\n",
    "conf.setAppName('ActividadSparkSQL_ebraganza')\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef19ca102de0bd28cf95f6c3cc755a74",
     "grade": false,
     "grade_id": "cell-08415507759b0533",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introducción a dataframes estructurados y operaciones sobre ellos\n",
    "\n",
    "Como ya se ha mencionado, en los siguientes ejercicis vamos a utilizar datos de Twitter que recolectamos durante las elecciones generales en España del 28 de abril de 2019. Como veremos, los tweets tienen una estructura interna bastante compleja que hemos simplificado un poco en esta práctica.\n",
    "\n",
    "Lo primero que vamos a aprender es cómo importar este tipo de datos a nuestro entorno. Uno de los tipos de archivos más comunes para guardar este formato de información es [la estructura JSON](https://en.wikipedia.org/wiki/JSON). Esta estructura permite guardar información en un texto plano de diferentes objetos siguiendo una estructura de diccionario donde cada campo tiene asignado una clave y un valor. La estructura puede ser anidada, o sea que una clave puede tener como valor otra estructura de tipo diccionario.\n",
    "\n",
    "Spark SQL permite leer datos de muchos formatos diferentes. Se os pide que [leáis el fichero JSON](https://archive.apache.org/dist/spark/docs/2.4.0/sql-data-sources-json.html) de la ruta ```/aula_M2.858/data/tweets28a_sample.json```. Este archivo contiene un pequeño *sample*, un 0.1% de la base de datos completa (en un siguiente apartado veremos cómo realizar este *sampleado*). En esta ocasión no se os pide especificar la estructura del dataframe ya que la función de lectura la inferirá automáticamente.\n",
    "\n",
    "**Ejemplo de lectura (Rellenar con lo correspondiente para la lectura del archivo json)**:\n",
    "\n",
    "```Python\n",
    "sqlContext = SQLContext(sc)\n",
    "tweets_sample = sqlContext.read.<FILL IN>\n",
    "\n",
    "print(\"Loaded dataset contains %d tweets\" % tweets_sample.count())\n",
    "```\n",
    "\n",
    "Para mostrar la estructura del dataset que acabamos de cargar, podéis obtener la información acerca de cómo está estructurado el DataTable utilizando el método ```printSchema()```. Tenéis que familiarizaros con esta estructura ya que será la que utilizaremos durante los próximos ejercicios. Recordad también que no todos los tweets tienen todos los campos, como por ejemplo la ubicación (campo ```place```). Cuando esto pasa el campo pasa a ser ```NULL```. Podéis ver más información sobre este tipo de datos en [este enlace](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object).\n",
    "\n",
    "Ahora debéis introducir el ejemplo de lectura con el `<FILL IN>` relleno según corresponda para la lectura del archivo JSON. Y, a continuación, mostraréis la estructura del dataset utilizando `printSchema()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ebcc8c05d7893b8cc832b9a3097e2e8",
     "grade": true,
     "grade_id": "cell-143481b773f8562c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Leer el archivo data frame\n",
    "ruta = '/aula_M2.858/data/tweets28a_sample.json'\n",
    "sqlContext = SQLContext(sc)\n",
    "tweets_sample = (sqlContext\n",
    "                 .read\n",
    "                 .json(ruta)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset contains 27268 tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded dataset contains %d tweets\" % tweets_sample.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- created_at: long (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- place: struct (nullable = true)\n",
      " |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- country_code: string (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- place_type: string (nullable = true)\n",
      " |-- retweeted_status: struct (nullable = true)\n",
      " |    |-- _id: string (nullable = true)\n",
      " |    |-- user: struct (nullable = true)\n",
      " |    |    |-- followers_count: long (nullable = true)\n",
      " |    |    |-- friends_count: long (nullable = true)\n",
      " |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |-- lang: string (nullable = true)\n",
      " |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |-- statuses_count: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- user: struct (nullable = true)\n",
      " |    |-- followers_count: long (nullable = true)\n",
      " |    |-- friends_count: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- screen_name: string (nullable = true)\n",
      " |    |-- statuses_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_sample.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0255313b05157ccb3814e810af047965",
     "grade": false,
     "grade_id": "cell-819d752224637bc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Queries sobre dataframes complejos\n",
    "\n",
    "A continuación vamos a ver como realizar consultas sobre el dataset de los tweets. Vamos a utilizar [sentencias *SQL*](https://www.w3schools.com/sql/default.asp) (como las utilizadas en la mayoría de bases de datos relacionales).\n",
    "\n",
    "Lo primero que se debe hacer es registrar el dataframe de tweets como una tabla de SQL. Para ello utilizaremos [sqlContext.registerDataFrameAsTable()](https://archive.apache.org/dist/spark/docs/api/python/pyspark.sql.html#pyspark.sql.SQLContext.registerDataFrameAsTable). Para ejecutar comandos sql solo teneis que utilizar el metodo sql() del objecto contexto, en este caso `sqlContext`.\n",
    "\n",
    "#### Queries a través del pipeline\n",
    "\n",
    "Las tablas de Spark SQL ofrecen otro mecanismo para aplicar las transformaciones y obtener resultados similares a los que se obtendría aplicando una consulta SQL. Por ejemplo, utilizando el siguiente pipeline obtendremos el texto de todos los tweets en español:\n",
    "\n",
    "```\n",
    "tweets_sample.where(\"lang == 'es'\").select(\"text\")\n",
    "```\n",
    "\n",
    "Que es equivalente a la siguiente sentencia SQL:\n",
    "\n",
    "```\n",
    "SELECT text\n",
    "FROM tweets_sample\n",
    "WHERE lang == 'es'\n",
    "```\n",
    "\n",
    "Podéis consultar el [API de spark SQL](https://archive.apache.org/dist/spark/docs/api/python/pyspark.sql.html) para encontrar más información sobre como utilizar las diferentes transformaciones en tablas.\n",
    "\n",
    "### **Ejercicio 5**: Análisis de Tweets mediante DataFrames y consultas SQL (*2 puntos*)\n",
    "\n",
    "Anteriormente ya has realizado la lectura del conjunto `tweets28a_sample.json` en formato JSON. Ahora deberás asegúrate de registrar el DataFrame como una tabla SQL llamada `tweets_sample`.\n",
    "\n",
    "***Nota:*** Debido a que es posible que ejecutes estas líneas de codigo várias veces, vamos a tomar la precaución de ejecutar el comando sql para eliminar tablas antes de que las crees, ya que puede existir la posibilidad de que ya existan.\n",
    "\n",
    "`sqlContext.sql(\"DROP TABLE IF EXISTS tweets_sample\")`\n",
    "\n",
    "A continuación, se pide crear una tabla y registrarla con el nombre ```users_agg``` con [la información agregada](https://www.w3schools.com/sql/sql_groupby.asp) de los usuarios que tengan definido su idioma (```user.lang```) como español (```es```). En concreto se pide que la tabla contenga las siguientes columnas:\n",
    "- **screen_name:** nombre del usuario\n",
    "- **friends_count:** número máximo (ver nota) de personas a las que sigue\n",
    "- **tweets:** número de tweets realizados\n",
    "- **followers_count:** número máximo (ver nota) personas que siguen al usuario.\n",
    "\n",
    "El orden en el cual se deben mostrar los registros es orden descendente acorde al número de tweets.\n",
    "\n",
    "***Nota:*** Es importante que te fijes que el nombre de *friends* y *followers* puede diferir a lo largo de la adquisición de datos. En este caso vamos a utilizar la función de agregación `MAX` sobre cada uno de estos campos para evitar segmentar el usuario en diversas instancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94b042131ca75243540d4dba151106e5",
     "grade": false,
     "grade_id": "cell-61484843695e0af4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "sqlContext.sql(\"DROP TABLE IF EXISTS tweets_sample\")\n",
    "sqlContext.registerDataFrameAsTable(tweets_sample, tableName= 'tweets_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+------+---------------+\n",
      "|    screen_name|friends_count|tweets|followers_count|\n",
      "+---------------+-------------+------+---------------+\n",
      "|       anaoromi|         6258|    16|           6774|\n",
      "|    RosaMar6254|         6208|    14|           6245|\n",
      "|        lyuva26|         3088|    13|           3732|\n",
      "|     carrasquem|          147|    12|            215|\n",
      "|PisandoFuerte10|         2795|    12|           1752|\n",
      "|       jasalo54|         1889|    11|            689|\n",
      "|  Rafa_eltorete|          908|     9|           1060|\n",
      "| locuspolitikus|        11261|     9|          10244|\n",
      "|      kikyosanz|          154|     9|            273|\n",
      "|  PabloChabolas|         4925|     9|           4042|\n",
      "|     Lordcrow11|         5002|     9|           3069|\n",
      "|      lolalailo|         4922|     9|           3738|\n",
      "|    DuroBelinda|         5242|     9|           5778|\n",
      "|        Fermirv|         3031|     8|           1731|\n",
      "| BlaancaNiieves|         7023|     8|          12630|\n",
      "| complementosCH|         2985|     8|           2740|\n",
      "|   rosavergar23|          900|     8|           1224|\n",
      "| Espanholimetro|         1637|     8|            708|\n",
      "|    SSarelvis67|         3287|     8|           2323|\n",
      "|   merchi_otero|          701|     8|            852|\n",
      "+---------------+-------------+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, max, sum, count, desc\n",
    "\n",
    "# Creación del DataFrame users_agg\n",
    "users_agg = (tweets_sample\n",
    "             .where(\"user.lang == 'es'\")\n",
    "             .select(\"user.screen_name\", \"user.friends_count\", \"text\", \"user.followers_count\")\n",
    "             .groupby(\"screen_name\")\n",
    "             .agg(\n",
    "                 max(\"friends_count\").alias(\"friends_count\"),\n",
    "                 count(\"text\").alias(\"tweets\"),\n",
    "                 max(\"followers_count\").alias(\"followers_count\")\n",
    "             )\n",
    "             .orderBy(desc(\"tweets\"))\n",
    "            )\n",
    "sqlContext.sql(\"DROP TABLE IF EXISTS users_agg\")\n",
    "sqlContext.registerDataFrameAsTable(users_agg, tableName= 'users_agg')\n",
    "users_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+------+---------------+\n",
      "|    screen_name|friends_count|tweets|followers_count|\n",
      "+---------------+-------------+------+---------------+\n",
      "|       anaoromi|         6258|    16|           6774|\n",
      "|    RosaMar6254|         6208|    14|           6245|\n",
      "|        lyuva26|         3088|    13|           3732|\n",
      "|     carrasquem|          147|    12|            215|\n",
      "|PisandoFuerte10|         2795|    12|           1752|\n",
      "|       jasalo54|         1889|    11|            689|\n",
      "|  Rafa_eltorete|          908|     9|           1060|\n",
      "| locuspolitikus|        11261|     9|          10244|\n",
      "|      kikyosanz|          154|     9|            273|\n",
      "|  PabloChabolas|         4925|     9|           4042|\n",
      "|     Lordcrow11|         5002|     9|           3069|\n",
      "|      lolalailo|         4922|     9|           3738|\n",
      "|    DuroBelinda|         5242|     9|           5778|\n",
      "|        Fermirv|         3031|     8|           1731|\n",
      "| BlaancaNiieves|         7023|     8|          12630|\n",
      "| complementosCH|         2985|     8|           2740|\n",
      "|   rosavergar23|          900|     8|           1224|\n",
      "| Espanholimetro|         1637|     8|            708|\n",
      "|    SSarelvis67|         3287|     8|           2323|\n",
      "|   merchi_otero|          701|     8|            852|\n",
      "+---------------+-------------+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creación del DataFrame users_agg opcion 2 usando sql.\n",
    "users_agg = (sqlContext.sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        user.screen_name as screen_name, \n",
    "        MAX(user.friends_count) as friends_count, \n",
    "        COUNT(text) as tweets, \n",
    "        MAX(user.followers_count) as followers_count\n",
    "    FROM tweets_sample\n",
    "    WHERE user.lang = 'es'\n",
    "    GROUP BY 1\n",
    "    ORDER BY tweets desc\n",
    "    \n",
    "    \"\"\"\n",
    ")\n",
    "            )\n",
    "users_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ddb6d1ff9d282bf041c958a51409b251",
     "grade": true,
     "grade_id": "cell-ef7edc9cd8f50aaa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f90e58b860adf6bbc5e9a736aa76ae40",
     "grade": false,
     "grade_id": "cell-707f689f738619d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A continuación recurriremos al [JOIN de tablas](https://www.w3schools.com/sql/sql_join.asp) para combinar la información entre tablas. Debes combinar la tabla `users_agg` y la tabla `tweets_sample` utilizando un `INNER JOIN` para obtener una nueva tabla con el nombre retweeted con la siguiente información:\n",
    "- ***screen_name:*** nombre de usuario\n",
    "- ***friends_count:*** número máximo de personas a las que sigue\n",
    "- ***followers_count:*** número máximo de personas que siguen al usuario.\n",
    "- ***tweets:*** número de tweets realizados por el usuario.\n",
    "- ***retweeted:*** número de retweets obtenidos por el usuario.\n",
    "- ***ratio_tweet_retweeted:*** ratio de retweets por número de tweets publicados $\\frac{retweets}{tweets}$\n",
    "\n",
    "La tabla resultante `retweeted` tiene que estar ordenada de manera descendente según el valor de la columna `ratio_tweet_retweeted`.\n",
    "\n",
    "Por último, utilizando queries a través de pipeline, debes crear una tabla `user_retweets` a partir de la tabla `tweets_sample`, utilizando transformaciones que contenga dos columnas:\n",
    "- ***screen_name:*** nombre de usuario\n",
    "- ***retweeted:*** número de retweets\n",
    "\n",
    "Ordena la tabla en orden descendente utilizando el valor de la columna ```retweeted```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eda20c4042b6abfcc721827bba89534c",
     "grade": false,
     "grade_id": "cell-d437d92649bff2c3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+------+---------------+---------+---------------------+\n",
      "|    screen_name|friends_count|tweets|followers_count|retweeted|ratio_tweet_retweeted|\n",
      "+---------------+-------------+------+---------------+---------+---------------------+\n",
      "|   Dori74176530|         1610|     1|             74|        2|                  2.0|\n",
      "| Marisa22208126|           36|     1|             21|        2|                  2.0|\n",
      "| Jhonnynecmonic|         9020|     6|           8694|        6|                  1.0|\n",
      "|     Jo_Herrero|         4747|     6|           3111|        6|                  1.0|\n",
      "|       28aOriol|         2103|     8|            873|        8|                  1.0|\n",
      "|      Orballo10|          147|     7|           1145|        7|                  1.0|\n",
      "|javiergarmon191|          448|     6|           1767|        6|                  1.0|\n",
      "|        dbt0170|          812|     7|            770|        7|                  1.0|\n",
      "|     carrasquem|          147|    12|            215|       12|                  1.0|\n",
      "|     astroman78|         1095|     7|           1238|        7|                  1.0|\n",
      "|  PabloChabolas|         4925|     9|           4042|        9|                  1.0|\n",
      "|AmparoDelacru13|         5725|     7|           5218|        7|                  1.0|\n",
      "|     Lordcrow11|         5002|     9|           3069|        9|                  1.0|\n",
      "|        mrh0099|          447|     7|            243|        7|                  1.0|\n",
      "| locuspolitikus|        11261|     9|          10244|        9|                  1.0|\n",
      "| IgualdadFFCSSE|         1192|     7|            685|        7|                  1.0|\n",
      "|      kikyosanz|          154|     9|            273|        9|                  1.0|\n",
      "|       LianaEHE|         5272|     8|           5014|        8|                  1.0|\n",
      "|     nusagatero|         4998|     7|           3829|        7|                  1.0|\n",
      "|       anap1958|          132|     8|            400|        8|                  1.0|\n",
      "+---------------+-------------+------+---------------+---------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JOIN DE TABLAS\n",
    "retweeted = (sqlContext.sql(\n",
    "    \"\"\"\n",
    "    \n",
    "    WITH \n",
    "        retweets as (\n",
    "        SELECT \n",
    "            user.screen_name as screen_name, \n",
    "            COUNT(retweeted_status._id) as retweeted\n",
    "        FROM tweets_sample\n",
    "        WHERE retweeted_status._id IS NOT NULL \n",
    "        GROUP BY 1\n",
    "        ORDER BY retweeted desc \n",
    "        )\n",
    "\n",
    "        SELECT \n",
    "            A.*, \n",
    "            B.retweeted,\n",
    "            ROUND(B.retweeted / NULLIF(A.tweets, 0) , 2) as ratio_tweet_retweeted \n",
    "        FROM users_agg A\n",
    "        INNER JOIN retweets B\n",
    "        ON A.screen_name = B.screen_name\n",
    "        ORDER BY ratio_tweet_retweeted DESC\n",
    "\n",
    "        \"\"\"\n",
    ")\n",
    "            )\n",
    "\n",
    "sqlContext.sql(\"DROP TABLE IF EXISTS retweeted\")\n",
    "sqlContext.registerDataFrameAsTable(retweeted, tableName= 'retweeted')\n",
    "retweeted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+\n",
      "|    screen_name|retweeted|\n",
      "+---------------+---------+\n",
      "|       anaoromi|       16|\n",
      "|     carrasquem|       12|\n",
      "|PisandoFuerte10|       12|\n",
      "|  Angel15268471|       11|\n",
      "|    RosaMar6254|       11|\n",
      "|       jasalo54|       11|\n",
      "|        lyuva26|       11|\n",
      "| locuspolitikus|        9|\n",
      "|     Lordcrow11|        9|\n",
      "|    DuroBelinda|        9|\n",
      "|      kikyosanz|        9|\n",
      "|      el_partal|        9|\n",
      "|  PabloChabolas|        9|\n",
      "|   Robi45852533|        9|\n",
      "|      lolalailo|        8|\n",
      "|       anap1958|        8|\n",
      "|    SSarelvis67|        8|\n",
      "|   merchi_otero|        8|\n",
      "| complementosCH|        8|\n",
      "| Espanholimetro|        8|\n",
      "+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Creación de user retweets\n",
    "from pyspark.sql.functions import avg, max, sum, count, desc\n",
    "\n",
    "# Creación del DataFrame users_agg\n",
    "users_retweets = (\n",
    "    tweets_sample\n",
    "             .where(\"retweeted_status._id is not NULL\")\n",
    "             .select(\"user.screen_name\", \"retweeted_status._id\")\n",
    "             .groupby(\"screen_name\")\n",
    "             .agg(\n",
    "                 count(\"_id\").alias(\"retweeted\"),\n",
    "             )\n",
    "             .orderBy(desc(\"retweeted\"))\n",
    "            )\n",
    "sqlContext.sql(\"DROP TABLE IF EXISTS users_retweets\")\n",
    "sqlContext.registerDataFrameAsTable(users_retweets, tableName= 'users_retweets')\n",
    "users_retweets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "520d74604bf7faa8b463da8b47307368",
     "grade": true,
     "grade_id": "cell-b54605adb4fc0173",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "865d5d56fdb14af4493bdd559b534c17",
     "grade": false,
     "grade_id": "cell-ee6926263623ddb2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Bases de datos HIVE y operaciones complejas\n",
    "\n",
    "Hasta ahora hemos estado trabajando con un pequeño sample de los tweets generados (el 0.1%). En esta parte de la actividad vamos a ver como trabajar y tratar con el dataset completo. Para ello vamos a utilizar tanto transformaciones sobre tablas como operaciones sobre RDD cuando sea necesario.\n",
    "\n",
    "Es importante tener en cuenta que muchas veces los datos con los que trabajamos se utilizarán en diversos proyectos. En lugar de manejar directamente los archivos, es más eficiente y organizado recurrir a una base de datos para gestionar la información. En el ecosistema de Hadoop, una de las bases de datos más utilizadas es [Apache Hive](https://hive.apache.org/). Sin embargo, es crucial entender que Hive no es una base de datos convencional. En realidad, funciona como un metastore que mapea archivos en el sistema de archivos distribuido de Hadoop (HDFS).\n",
    "\n",
    "Esto significa que Hive no almacena los datos en su propio formato de base de datos, sino que actúa como una interfaz que permite a los usuarios ejecutar consultas SQL sobre los datos almacenados en HDFS. Esto proporciona una forma eficiente de acceder y manipular grandes volúmenes de datos distribuidos sin necesidad de moverlos o convertirlos a un formato tradicional de base de datos.\n",
    "\n",
    "La manera de acceder a esta base de datos es creando un contexto Hive de manera muy similar a como declaramos un contexto SQL. Primero vamos a declarar un variable ```hiveContext``` instanciándola como un objeto de la classe ```HiveContext```. Acto seguido vamos a comprobar cuantas tablas están registradas en este contexto.\n",
    "\n",
    "**Esquema**\n",
    "```Python\n",
    "hiveContext = <FILL IN>\n",
    "hiveContext.tables().show()\n",
    "```\n",
    "\n",
    "Ejecuta este esquema con el FILL IN rellenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "349d58c49dfaf1f165dbc6a9192e1602",
     "grade": true,
     "grade_id": "cell-bab26dda42048abd",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-----------+\n",
      "|database|         tableName|isTemporary|\n",
      "+--------+------------------+-----------+\n",
      "| default|            d_pais|      false|\n",
      "| default| d_tipo_habitacion|      false|\n",
      "| default|      province_28a|      false|\n",
      "| default|         tweets28a|      false|\n",
      "| default|     tweets28afull|      false|\n",
      "| default|tweets28a_sample25|      false|\n",
      "| default|         user_info|      false|\n",
      "| default|     user_info_old|      false|\n",
      "|        |         retweeted|       true|\n",
      "|        |     tweets_sample|       true|\n",
      "|        |         users_agg|       true|\n",
      "|        |    users_retweets|       true|\n",
      "+--------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "hiveContext = HiveContext(sc)\n",
    "hiveContext.tables().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9436b334e3d485903a2cc31294b9af27",
     "grade": false,
     "grade_id": "cell-cc6dc65ad219a2f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Observad que ahora mismo tenemos varias tablas registradas en este contexto. Algunas de ellas no temporales y dos temporales, las que hemos registrado previamente. Por tanto, sqlContext y hiveContext están conectados (es la misma sesión).\n",
    "\n",
    "### Más allá de las transformaciones SQL\n",
    "\n",
    "Algunas veces vamos a necesitar obtener resultados que precisan operaciones que van más allá de lo que podemos conseguir (cómodamente) utilizando el lenguaje SQL. En esta parte de la práctica vamos a practicar cómo pasar de una tabla a un RDD, para hacer operaciones complejas, y luego volver a pasar a una tabla.\n",
    "\n",
    "Ahora viene la parte interesante. Una tabla puede convertirse en un RDD a través del atributo ```.rdd```. Este atributo guarda la información de la tabla en una lista donde cada elemento es un [objeto del tipo ```Row```](https://archive.apache.org/dist/spark/docs/2.4.0/api/python/pyspark.sql.html#pyspark.sql.Row). Los objetos pertenecientes a esta clase pueden verse como diccionarios donde la información de las diferentes columnas queda reflejada en forma de atributo. Por ejemplo, imaginad que tenemos una tabla con dos columnas, nombre y apellido, si utilizamos el atributo ```.rdd``` de dicha tabla obtendremos una lista con objetos del tipo row donde cada objeto tiene dos atributos: nombre y apellido. Para acceder a los atributos solo tenéis que utilizar la sintaxis *punto* de Python, e.g., ```row.nombre``` o ```row.apellido```.\n",
    "\n",
    "### **Ejercicio 6**: Análisis de Tweets Geolocalizados (*1.5 puntos*)\n",
    "\n",
    "Dada la tabla de tweets `tweets28a_sample25`, debes crear una variable `tweets` con `hiveContext` utilizando el método `table()`. Utilizando una sentencia SQL, se requiere extraer información sobre los tweets que contienen datos geolocalizados (es decir, aquellos donde el campo `place` no es nulo) y determinar cuántos tweets se han generado desde cada lugar. Los resultados deben ser presentados en orden descendente por la cantidad de tweets.\n",
    "\n",
    "**Esquema sentencia sql**\n",
    "```Python\n",
    "tweets_place = hiveContext.sql(<FILL IN>)\n",
    "```\n",
    "\n",
    "A continuación, crea una tabla llamada `tweets_place` que contenga dos columnas:\n",
    "\n",
    "- ***name:*** nombre del lugar desde donde se ha generado el tweet.\n",
    "- ***tweets:*** número total de tweets realizados en dicho lugar.\n",
    "\n",
    "Finalmente, muestra los 10 lugares con mayor número de tweets en la tabla resultante.\n",
    "\n",
    "Adicionalmente, crea una tabla llamada `tweets_geo` que contenga únicamente los tweets que tienen información de geolocalización, y asegúrate de que incluya el nombre del lugar. A partir de esta tabla, crea un objeto ```tweets_place_rdd``` que contenga una lista de tuplas con la información ```(name, tweets)``` sobre el nombre del lugar y el número de tweets generados desde allí.\n",
    "\n",
    "Una vez generado este RDD vamos a crear una tabla que llamarás también `tweets_place`. El primer paso es generar por cada tupla un objeto Row que contenga un atributo ```name``` y un atributo ```tweets```. Ahora solo tenéis que aplicar el método ```toDF()``` para generar una tabla. Ordenad las filas de esta tabla por el número de tweets en orden descendente.\n",
    "\n",
    "El ejercicio deberá realizarse combinando tanto sentencias SQL como RDD en Apache Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----+-----+--------------------+--------------------+--------------------+\n",
      "|                _id|         created_at|lang|place|    retweeted_status|                text|                user|\n",
      "+-------------------+-------------------+----+-----+--------------------+--------------------+--------------------+\n",
      "|1117169839657844736|2019-04-13 22:57:00|  en| null|[1117009066402955...|RT @DearAuntCrabb...|[329, 871, 547969...|\n",
      "|1117169840802934787|2019-04-13 22:57:00|  es| null|[1117037292458262...|RT @PAH_Burgos: #...|[18, 17, 88521307...|\n",
      "|1117169840870100994|2019-04-13 22:57:00|  es| null|[1116682791503192...|RT @ViajesFalcon:...|[1270, 356, 76286...|\n",
      "|1117169840886882304|2019-04-13 22:57:00|  es| null|[1117157909568397...|RT @AiniApgg: Est...|[3887, 3860, 6100...|\n",
      "|1117169841985683456|2019-04-13 22:57:00|  es| null|[1117083000343232...|RT @Santi_ABASCAL...|[137, 593, 289042...|\n",
      "+-------------------+-------------------+----+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Primer vistazo de la tabla\n",
    "tweets = hiveContext.table(\"tweets28a_sample25\")\n",
    "tweets.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22137856a6a8329e81b4df4837db9362",
     "grade": false,
     "grade_id": "cell-17e6c49377cef82f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|       name|tweets|\n",
      "+-----------+------+\n",
      "|     Madrid|  4911|\n",
      "|  Barcelona|  3481|\n",
      "|    Sevilla|   959|\n",
      "|   Valencia|   689|\n",
      "|   Zaragoza|   597|\n",
      "|Villamartín|   570|\n",
      "|     Málaga|   546|\n",
      "|     Murcia|   461|\n",
      "|      Palma|   416|\n",
      "|   Alicante|   407|\n",
      "+-----------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tweets place\n",
    "tweets_place = (\n",
    "    hiveContext\n",
    "    .sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        place.name as name,\n",
    "        count(text) as tweets\n",
    "    FROM tweets28a_sample25\n",
    "    WHERE place is not null\n",
    "    GROUP BY 1\n",
    "    ORDER BY 2 DESC\n",
    "    \"\"\"\n",
    "    )\n",
    "        )\n",
    "hiveContext.sql(\"DROP TABLE IF EXISTS tweets_place\")\n",
    "hiveContext.registerDataFrameAsTable(tweets_place, tableName= 'tweets_place')\n",
    "\n",
    "tweets_place.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----+--------------------+----------------+--------------------+--------------------+\n",
      "|                _id|         created_at|lang|               place|retweeted_status|                text|                user|\n",
      "+-------------------+-------------------+----+--------------------+----------------+--------------------+--------------------+\n",
      "|1117170058671923200|2019-04-13 22:57:52|  es|[[[[[2.052477, 41...|            null|@nasholop @PSOE N...|[1084, 1200, 8904...|\n",
      "|1117170246685736960|2019-04-13 22:58:37|  es|[[[[[-4.654915, 4...|            null|@luttor007 @Sexta...|[509, 1014, 18878...|\n",
      "|1117170260384395264|2019-04-13 22:58:40|  es|[[[[[-1.385233, 3...|            null|@JORDIARCE Aquí s...|[127, 314, 931553...|\n",
      "|1117170273722294273|2019-04-13 22:58:43|  es|[[[[[-5.014957, 3...|            null|@DTrolera @Irene_...|[3027, 3139, 2982...|\n",
      "|1117170471101968384|2019-04-13 22:59:30|  es|[[[[[2.052477, 41...|            null|@SoyDeDerechas @S...|[1263, 1582, 8065...|\n",
      "+-------------------+-------------------+----+--------------------+----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear la tabla `tweets_geo` con tweets que contienen geolocalización\n",
    "tweets_geo = hiveContext.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM tweets28a_sample25\n",
    "    WHERE place IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "hiveContext.sql(\"DROP TABLE IF EXISTS tweets_geo\")\n",
    "hiveContext.registerDataFrameAsTable(tweets_geo, tableName= 'tweets_geo')\n",
    "tweets_geo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Madrid', tweets=4911),\n",
       " Row(name='Barcelona', tweets=3481),\n",
       " Row(name='Sevilla', tweets=959),\n",
       " Row(name='Valencia', tweets=689),\n",
       " Row(name='Zaragoza', tweets=597),\n",
       " Row(name='Villamartín', tweets=570),\n",
       " Row(name='Málaga', tweets=546),\n",
       " Row(name='Murcia', tweets=461),\n",
       " Row(name='Palma', tweets=416),\n",
       " Row(name='Alicante', tweets=407)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir la tabla `tweets_place` en un RDD\n",
    "tweets_place_rdd = tweets_place.rdd.map(lambda x: Row(name=x[0], tweets=x[1]))\n",
    "\n",
    "# Mostrar una muestra del RDD para verificar su contenido\n",
    "tweets_place_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to table\n",
    "tweets_place = tweets_place_rdd.toDF()\n",
    "hiveContext.sql(\"DROP TABLE IF EXISTS tweets_place\")\n",
    "hiveContext.registerDataFrameAsTable(tweets_place, tableName= 'tweets_place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df62d300ffd9be24e43f21aedb39a89d",
     "grade": true,
     "grade_id": "cell-2997ae4966dc4f47",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17dd9f85fe3b2d6455d479a8fd9f2039",
     "grade": false,
     "grade_id": "cell-2e89c0fb2e623367",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Sampling\n",
    "\n",
    "En muchas ocasiones, antes de lanzar costosos procesos, es una práctica habitual tratar con un pequeño conjunto de los datos para investigar algunas propiedades o simplemente para depurar nuestros algoritmos, a esta tarea se la llama sampling. En esta parte de la práctica vamos a ver los dos principales métodos de sampling y cómo utilizarlos.\n",
    "\n",
    "### Nota:\n",
    "Para producir un gráfico de barras utilizando [Pandas](https://pandas.pydata.org/) donde se muestre la información que acabáis de generar. Primero transformad la tabla a pandas utilizando el método `toPandas()`. Plotead la tabla resultante utilizando [la funcionalidad gráfica de pandas.](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html)\n",
    "\n",
    "### Homogéneo\n",
    "\n",
    "El primer sampling que vamos a ver es [el homogeneo](https://en.wikipedia.org/wiki/Simple_random_sample). Este sampling se basta en simplemente escoger una fracción de la población seleccionando aleatoriamente elementos de esta.\n",
    "\n",
    "Primero de todo vamos a realizar un sampling homogéneo del 1% de los tweets generados en periodo electoral sin reemplazo. Guardad en una variable ```tweets_sample``` este sampling utilizando el método ```sample``` descrito en la [API de pyspark SQL](https://spark.apache.org/docs/2.4.0/api/python/pyspark.sql.html). El seed que vais a utilizar para inicializar el generador aleatorio es 42.\n",
    "\n",
    "**Esquema**\n",
    "```Python\n",
    "seed = 42\n",
    "fraction = 0.01\n",
    "\n",
    "tweets_sample = tweets.<FILL IN>\n",
    "\n",
    "print(\"Number of tweets sampled: {0}\".format(tweets_sample.count()))\n",
    "```\n",
    "\n",
    "### **Ejercicio 7**: Análisis del Patrón de Actividad Horaria en Twitter (*1 puntos*)\n",
    "A partir de una muestra del 1% de los tweets disponibles, se desea analizar el patrón de uso diario de Twitter, prestando especial atención a la actividad horaria. El objetivo es calcular y visualizar el promedio de tweets generados en cada hora del día. Para ello se debe crear una tabla ```tweets_timestamp``` con la información:\n",
    "- ***created_at***: timestamp de cuando se publicó el tweet.\n",
    "- ***hour***: a que hora del dia corresponde.\n",
    "- ***day***: Fecha en formato MM-dd-YY\n",
    "\n",
    "La tabla tiene que estar en orden ascendente según la columna `created_at`\n",
    "\n",
    "**Pista**: Para crear las columnas \"hour\" y \"day\" en tu tabla tweets_timestamp, puedes utilizar withColumn(). La función ```hour``` os servirá para extraer la hora del timestamp y la función ```date_format``` os permitirá generar la fecha.\n",
    "\n",
    "A continuación, utiliza la muestra de tweets para extraer la hora y fecha de publicación, y a partir de esa información, determina cuántos tweets se generan por hora, debes crear una tabla `tweets_hour_day` a partir de esta información.\n",
    "\n",
    "Por último, solo nos queda hacer una agregación por hora para conseguir el promedio de tweets por hora. Tenéis que generar una tabla ```tweets_hour``` con la información:\n",
    "- ***hour:*** Hora\n",
    "- ***tweets:*** Promedio de tweets realizados\n",
    "\n",
    "Recordad que estamos trabajando con un sample del 1% por tanto tenéis que corregir la columna ```tweets``` para que refleje el promedio que deberíamos esperar en el conjunto completo de tweets. La tabla tiene que estar ordenada en orden ascendente de hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a412b274010d283eebb1b262ab4e49a",
     "grade": false,
     "grade_id": "cell-9e4ac72a18212c9f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets sampled: 63888\n"
     ]
    }
   ],
   "source": [
    "# Sample de 1%\n",
    "seed = 42\n",
    "fraction = 0.01\n",
    "\n",
    "tweets_sample = tweets.sample(seed=seed, fraction=fraction, withReplacement=False)\n",
    "\n",
    "print(\"Number of tweets sampled: {0}\".format(tweets_sample.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----+-----+--------------------+--------------------+--------------------+\n",
      "|                _id|         created_at|lang|place|    retweeted_status|                text|                user|\n",
      "+-------------------+-------------------+----+-----+--------------------+--------------------+--------------------+\n",
      "|1117169844984610817|2019-04-13 22:57:01|  es| null|                null|@Earco1977 Pues a...|[5893, 4783, 5090...|\n",
      "|1117169933849247744|2019-04-13 22:57:22|  en| null|[1117165317254467...|RT @AOC: “They’re...|[105, 51, 1815836...|\n",
      "|1117169944570023938|2019-04-13 22:57:25|  ca| null|[1117142964185309...|RT @ABalagu: El v...|[655, 787, 583056...|\n",
      "|1117170315405217794|2019-04-13 22:58:53|  es| null|[1117168749583523...|RT @anachacong: @...|[155, 225, 998627...|\n",
      "|1117170324691456003|2019-04-13 22:58:56|  es| null|[1117069867633520...|RT @Pablo_Iglesia...|[4493, 4488, 2530...|\n",
      "+-------------------+-------------------+----+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_sample.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+--------+\n",
      "|         created_at|hour|     day|\n",
      "+-------------------+----+--------+\n",
      "|2019-04-12 03:06:25|   3|04-12-19|\n",
      "|2019-04-12 05:08:47|   5|04-12-19|\n",
      "|2019-04-12 09:15:02|   9|04-12-19|\n",
      "|2019-04-12 09:38:31|   9|04-12-19|\n",
      "|2019-04-12 10:46:02|  10|04-12-19|\n",
      "+-------------------+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extraer dia y hora del tweet\n",
    "from pyspark.sql.functions import hour, col, date_format, count, avg, round\n",
    "tweets_timestamp = (tweets_sample\n",
    "                    .select(\"created_at\")\n",
    "                    .withColumn(\"hour\", hour(col(\"created_at\")))\n",
    "                    .withColumn(\"day\", date_format(col(\"created_at\"), format=\"MM-dd-YY\"))\n",
    "                    .orderBy(\"created_at\")\n",
    "                   )\n",
    "\n",
    "tweets_timestamp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets hour day\n",
    "tweets_hour_day = (\n",
    "    tweets_timestamp\n",
    "    .groupBy(\"day\", \"hour\")\n",
    "    .agg( (count(\"created_at\")) \n",
    "    .alias(\"tweets\"))\n",
    "    .orderBy(\"day\", \"hour\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+------+\n",
      "|     day|hour|tweets|\n",
      "+--------+----+------+\n",
      "|04-12-19|   3|     1|\n",
      "|04-12-19|   5|     1|\n",
      "|04-12-19|   9|     2|\n",
      "|04-12-19|  10|    12|\n",
      "|04-12-19|  11|    93|\n",
      "+--------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_hour_day.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|hour|avg_tweets|\n",
      "+----+----------+\n",
      "|   0|   26188.9|\n",
      "|   1|   13161.1|\n",
      "|   2|    6227.8|\n",
      "|   3|    3016.7|\n",
      "|   4|    2235.3|\n",
      "|   5|    1866.7|\n",
      "|   6|    3217.6|\n",
      "|   7|    6729.4|\n",
      "|   8|   10952.9|\n",
      "|   9|   13455.6|\n",
      "|  10|   14405.6|\n",
      "|  11|   15133.3|\n",
      "|  12|   16011.1|\n",
      "|  13|   16422.2|\n",
      "|  14|   16877.8|\n",
      "|  15|   18016.7|\n",
      "|  16|   17494.4|\n",
      "|  17|   16461.1|\n",
      "|  18|   16622.2|\n",
      "|  19|   17433.3|\n",
      "|  20|   18838.9|\n",
      "|  21|   20711.1|\n",
      "|  22|   30411.1|\n",
      "|  23|   34327.8|\n",
      "+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_hour = tweets_hour_day.groupby(\"hour\").agg( round(avg(\"tweets\") / 0.01, 1).alias(\"avg_tweets\")).orderBy(\"hour\")\n",
    "tweets_hour.show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da0955911ded10201a2997d1fb58c859",
     "grade": true,
     "grade_id": "cell-dbbc7b6886dfb6c4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5464caf75b78a11bf6daf5839a3ea784",
     "grade": false,
     "grade_id": "cell-28db2ef4b5016901",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Estratificado\n",
    "\n",
    "En muchas ocasiones el sampling homogéneo no es adecuado ya que por la propia estructura de los datos determinados segmentos pueden estar sobre-representadas. Este es el caso que observamos en los tweets donde las grandes áreas urbanas están sobrerepresentadas si lo comparamos con el volumen de población. En esta actividad vamos a ver cómo aplicar esta técnica al dataset de tweets, para obtener un sampling que respete la proporción de diputados por provincia.\n",
    "\n",
    "En España, el proceso electoral asigna un volumen de diputados a cada provincia que depende de la población y de un porcentaje mínimo asignado por ley. En el contexto Hive que hemos creado previamente (```hiveContext```) podemos encontrar una tabla (```province_28a```) que contiene información sobre las circunscripciones electorales. Cargad ésta tabla en una variable con nombre ```province```.  Cargad esta tabla en una variable con nombre ```province```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "746d9729322ecb2c4cca732de281fb70",
     "grade": true,
     "grade_id": "cell-ef29acbef76f9bcc",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------------+----------+---------+\n",
      "|    capital|   province|              ccaa|population|diputados|\n",
      "+-----------+-----------+------------------+----------+---------+\n",
      "|     Teruel|     Teruel|            Aragón|     35691|        3|\n",
      "|      Soria|      Soria|   Castilla y León|     39112|        2|\n",
      "|    Segovia|    Segovia|   Castilla y León|     51683|        3|\n",
      "|     Huesca|     Huesca|            Aragón|     52463|        3|\n",
      "|     Cuenca|     Cuenca|Castilla-La Mancha|     54898|        3|\n",
      "|      Ávila|      Ávila|   Castilla y León|     57697|        3|\n",
      "|     Zamora|     Zamora|   Castilla y León|     61827|        3|\n",
      "|Ciudad Real|Ciudad Real|Castilla-La Mancha|     74743|        5|\n",
      "|   Palencia|   Palencia|   Castilla y León|     78629|        3|\n",
      "| Pontevedra| Pontevedra|           Galicia|     82802|        7|\n",
      "|     Toledo|     Toledo|Castilla-La Mancha|     84282|        6|\n",
      "|Guadalajara|Guadalajara|Castilla-La Mancha|     84910|        3|\n",
      "|      Ceuta|      Ceuta|             Ceuta|     85144|        1|\n",
      "|    Melilla|    Melilla|           Melilla|     86384|        1|\n",
      "|    Cáceres|    Cáceres|       Extremadura|     96098|        4|\n",
      "|       Lugo|       Lugo|           Galicia|     98025|        4|\n",
      "|     Girona|     Girona|          Cataluña|    100266|        6|\n",
      "|     Orense|     Orense|           Galicia|    105505|        4|\n",
      "|       Jaén|       Jaén|         Andalucía|    113457|        5|\n",
      "|      Cádiz|      Cádiz|         Andalucía|    116979|        9|\n",
      "+-----------+-----------+------------------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carga de province\n",
    "province = hiveContext.table(\"province_28a\")\n",
    "\n",
    "province.limit(52).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|  name|tweets|\n",
      "+------+------+\n",
      "|Teruel|     8|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_place.where(\"name='Teruel'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c5f0ec6109ce43c0d1f90eb77d180d5",
     "grade": false,
     "grade_id": "cell-7d381e80e8b40560",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "assert province.count() == 52, \"Incorrect answer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c43f9d88f5b070f3b6a02a2ac2f1f98a",
     "grade": false,
     "grade_id": "cell-12bff98437b3005c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Para hacer un sampling estratificado lo primero que tenemos que hacer es determinar la fracción que queremos asignar a cada categoría. En este caso queremos una fracción que haga que la ratio tweets diputado sea igual para todas las capitales de provincia. Debemos tener en cuenta que la precisión de la geolocalización en Twitter es normalmente a nivel de ciudad. Por eso, para evitar incrementar la complejidad del ejercicio, vamos a utilizar los tweets en capitales de provincia como proxy de los tweets en toda la provincia.\n",
    "\n",
    "### **Ejercicio 8**: Análisis de la Relación entre Tweets y Diputados por Provincia (*0.75 puntos*)\n",
    "\n",
    "Lo primero que tenéis que hacer es crear un tabla ```info_tweets_province``` que debe contener:\n",
    "- ***capital:*** nombre de la capital de provincia.\n",
    "- ***tweets:*** número de tweets geolocalizados en cada capital\n",
    "- ***diputados:*** diputados que asignados a la provincia.\n",
    "- ***ratio_tweets_diputado:*** número de tweets por diputado.\n",
    "\n",
    "Debéis ordenar la lista por ```ratio_tweets_diputado``` en orden ascendente.\n",
    "\n",
    "***Nota:*** Podéis realizar este ejercicio de muchas maneras, probablemente la más fácil es utilizar la tabla ```tweets_place``` que habéis generado en el ejercicio 5. Recordad cómo utilizar el ```join()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad8f83e851785288ac67966c35b703f4",
     "grade": false,
     "grade_id": "cell-79efcec5c58604f2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+---------------------+\n",
      "|   capital|tweets|diputados|ratio_tweets_diputado|\n",
      "+----------+------+---------+---------------------+\n",
      "|    Teruel|     8|        3|   2.6666666666666665|\n",
      "|Pontevedra|    29|        7|    4.142857142857143|\n",
      "|    Zamora|    23|        3|    7.666666666666667|\n",
      "|    Huesca|    26|        3|    8.666666666666666|\n",
      "|   Segovia|    28|        3|    9.333333333333334|\n",
      "+----------+------+---------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tweets province \n",
    "tweets_place = hiveContext.table(\"tweets_place\")\n",
    "info_tweets_province = (tweets_place\n",
    "                        .select(col(\"name\").alias(\"capital\"), \"tweets\")\n",
    "                        .join(province.select(\"capital\", \"diputados\"), on=\"capital\", how=\"inner\")\n",
    "                        .withColumn(\"ratio_tweets_diputado\",  col(\"tweets\") /col(\"diputados\")  )\n",
    "                        .orderBy(\"ratio_tweets_diputado\")\n",
    "                       )\n",
    "\n",
    "# VARIABLES DADAS (Las utilizaremos después)\n",
    "output = info_tweets_province.first()\n",
    "maximum_ratio = floor(output.ratio_tweets_diputado * 100) / 100\n",
    "info_tweets_province.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4043c385d0ec50ffd9db27e3480f0973",
     "grade": true,
     "grade_id": "cell-b3022ef230864c39",
     "locked": true,
     "points": 0.4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5f7dd10a88a83874822f9c7f5b937b2",
     "grade": false,
     "grade_id": "cell-565f4ca847f1d4bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A continuación, vamos a necesitar es un diccionario con nombre ```ratios``` donde cada capital de provincia es una llave y su valor asociado es la fracción de tweets que vamos a samplear. En este caso lo que queremos es que la ratio de tweets por cada diputado sea similar para cada capital de provincia.\n",
    "\n",
    "Como queremos que el sampling sea lo más grande posible y no queremos que ninguna capital este infrarepresentada el ratio de tweets por diputado será el valor más pequeño podéis observar en la tabla ```info_tweets_province```, que corresponde a 11.66 tweets por diputado en Teruel. Tenéis este valor guardado en la variable ```maximum_ratio```.\n",
    "\n",
    "*Nota:* El método ```collectAsMap()``` transforma un PairRDD en un diccionario.\n",
    "\n",
    "Por último, genera una tabla ```geo_tweets``` con todos los tweets geolocalizados. Ahora ya estamos en disposición de hacer el sampling estratificado por población. Para ello podéis utilizar el método ```sampleBy()```. Utilizad 42 como seed del generador pseudoaleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df13bdefb79e493cb9bbed8f66a4f6a0",
     "grade": false,
     "grade_id": "cell-1106beacc9ee80b3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "881"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear el diccionario 'ratios' con la fracción de tweets que se samplearán para cada capital\n",
    "ratios = info_tweets_province.rdd \\\n",
    "    .map(lambda row: (row[\"capital\"], maximum_ratio / row[\"ratio_tweets_diputado\"])) \\\n",
    "    .collectAsMap()\n",
    "\n",
    "geo_tweets = tweets.sampleBy(\"place.name\", fractions=ratios, seed=42)\n",
    "geo_tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiveContext.sql(\"DROP TABLE IF EXISTS geo_tweets\")\n",
    "hiveContext.registerDataFrameAsTable(geo_tweets, tableName= 'geo_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df5eb5707268f61e79d524aebb93e35e",
     "grade": true,
     "grade_id": "cell-3ddacba93fc16767",
     "locked": true,
     "points": 0.35,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02bae41e7474447c18a1f9ed4580dfcc",
     "grade": false,
     "grade_id": "cell-d8e5effe60498577",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introducción a los datos relacionales\n",
    "\n",
    "El hecho de trabajar con una base de datos que contiene información generada en una red social nos permite introducir el concepto de datos relacionales. Podemos definir datos relacionales como aquellos en los que existen relaciones entre las entidades que constituyen la base de datos. Si estas relaciones son binarias, relaciones 1 a 1, podemos representar las relaciones como un grafo compuesto por un conjunto de vértices $\\mathcal{V}$ y un conjunto de aristas $\\mathcal{E}$ que los relacionan.\n",
    "\n",
    "En el caso de grafos que emergen de manera orgánica, este tipo de estructura va más allá de los grafos regulares que seguramente conocéis. Este tipo de estructuras se conocen como [redes complejas](https://es.wikipedia.org/wiki/Red_compleja). El estudio de la estructura y dinámicas de este tipo de redes ha contribuido a importantes resultados en campos tan dispares como la física, la sociología, la ecología o la medicina.\n",
    "\n",
    "![complex_network](https://images.squarespace-cdn.com/content/5150aec6e4b0e340ec52710a/1364574727391-XVOFAB9P6GHKTDAH6QTA/lastfm_800_graph_white.png?content-type=image%2Fpng)\n",
    "\n",
    "En esta última parte de la práctica vamos a trabajar con este tipo de datos. En concreto vamos a modelar uno de las posibles relaciones presentes en el dataset, la red de retweets.\n",
    "\n",
    "#### Construcción de la edgelist\n",
    "\n",
    "Lo primero se os pide es que generéis la red. Hay diversas maneras de representar una red compleja, por ejemplo, si estuvierais interesados en trabajar en ellas desde el punto de vista teórico, la manera más habitual de representarlas es utilizando una [matriz de adyacencia](https://es.wikipedia.org/wiki/Matriz_de_adyacencia). En esta práctica vamos a centrarnos en el aspecto computacional, una de las maneras de más eficientes (computacionalmente hablando) de representar una red es mediante su [*edge list*](https://en.wikipedia.org/wiki/Edge_list), una tabla que especifica la relación a parejas entre las entidades.\n",
    "\n",
    "Las relaciones pueden ser bidireccionales o direccionales y tener algún peso asignado o no (weighted or unweighted). En el caso que nos ocupa, estamos hablando de una red dirigida, un usuario retuitea a otro, y podemos pensarla teniendo en cuenta cuántas veces esto ha pasado.\n",
    "\n",
    "#### Centralidad de grado\n",
    "\n",
    "Uno de los descriptores más comunes en el análisis de redes es el grado. El grado cuantifica cuántas aristas están conectadas a cada vértice~s~. En el caso de redes dirigidas como la que acabamos de crear este descriptor está descompuesto en el:\n",
    "- **in degree**: cuantas aristas apuntan al nodo\n",
    "- **out degree**: cuantas aristas salen del nodo\n",
    "\n",
    "Si haces un ranquing de estos valores vais a obtener una medida de centralidad, la [centralidad de grado](https://en.wikipedia.org/wiki/Centrality#Degree_centrality), de cada uno de los nodos.\n",
    "\n",
    "### **Ejercicio 9**: Análisis de Interacciones de Retweets y Grados de Usuario (*0.75 puntos*)\n",
    "\n",
    "A partir de una muestra homogénea del 1% de los tweets, con la semilla 42 para garantizar la reproducibilidad, realiza un análisis de las interacciones de retweets entre usuarios en la red social.\n",
    "\n",
    "**Esquema**\n",
    "```Python\n",
    "seed = 42\n",
    "sample = tweets.<FILL IN>\n",
    "```\n",
    "Crea una tabla ```edgelist``` con la siguiente información:\n",
    "- ***src:*** usuario que retuitea\n",
    "- ***dst:*** usuario que es retuiteado\n",
    "- ***weight:*** número de veces que un usuario retuitea a otro.\n",
    "\n",
    "Filtrar el resultado para que contenga sólo las relaciones con un weight igual o mayor a dos.\n",
    "\n",
    "A continuación, genera una tabla `outDegree` con la información:\n",
    "- ***screen_name:*** nombre del usuario.\n",
    "- ***outDegree:*** out degree del nodo.\n",
    "\n",
    "Ordenado la tabla por out degree en orden descendente.\n",
    "\n",
    "Se os pide ahora que generéis una tabla `inDegree` con la información:\n",
    "- ***screen_name:*** nombre del usuario.\n",
    "- ***inDegree:*** in degree del nodo.\n",
    "\n",
    "Ordenad la tabla por in degree en orden descendente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05385651a3f9074c60f08ae4cd9a96b1",
     "grade": false,
     "grade_id": "cell-b61e1a6ae475959b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets sampled: 63888\n"
     ]
    }
   ],
   "source": [
    "# Sample de 1%\n",
    "seed = 42\n",
    "fraction = 0.01\n",
    "\n",
    "sample = tweets.sample(seed=seed, fraction=fraction, withReplacement=False)\n",
    "\n",
    "print(\"Number of tweets sampled: {0}\".format(sample.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+------+\n",
      "|            src|           dst|weight|\n",
      "+---------------+--------------+------+\n",
      "| Olga_Hurtado66|    rcabrero75|     2|\n",
      "|        moxente|     alonso_dm|     2|\n",
      "|    gpscongreso|          PSOE|     3|\n",
      "|       mr_manco|         _ju1_|     2|\n",
      "|      arantzagg|        iunida|     2|\n",
      "| Maria_pilar_ga|      ppmadrid|     2|\n",
      "| soniapillado70|          PSOE|     2|\n",
      "|       7Josean7|  ahorapodemos|     2|\n",
      "|   RobertPastor| AlbanoDante76|     2|\n",
      "|      GomasDani|  fjosealcaraz|     2|\n",
      "|  desapabullada| Santi_ABASCAL|     2|\n",
      "|enriquelopez_es|      ivanedlm|     2|\n",
      "|     Bill21Bill|    Bill21Bill|     2|\n",
      "|     javalonseo| Albert_Rivera|     2|\n",
      "|Sociali17641882|          PSOE|     2|\n",
      "|  eajpnvbizkaia|        eajpnv|     2|\n",
      "|        Llago14|Rafael21148030|     2|\n",
      "|       JUKAROLO|      KilianCD|     2|\n",
      "|   TarantanoVII|    mabellogar|     2|\n",
      "|    NinesmNines|    maxpradera|     2|\n",
      "+---------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edgelist = (sample\n",
    "            .where(\"retweeted_status is not null\")\n",
    "            .groupBy(col(\"user.screen_name\").alias(\"src\"), col(\"retweeted_status.user.screen_name\").alias(\"dst\"))\n",
    "            .agg(\n",
    "                count(\"_id\").alias(\"weight\")\n",
    "            )\n",
    "            .where(\"weight >= 2\")\n",
    "           )\n",
    "edgelist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+\n",
      "|    screen_name|outDegree|\n",
      "+---------------+---------+\n",
      "|  antoniobb1953|        3|\n",
      "|    Manudocalin|        3|\n",
      "|       cukianaa|        2|\n",
      "|    Karmaleonic|        2|\n",
      "|    mariaje1956|        2|\n",
      "|    RosaMar6254|        2|\n",
      "|     Nacho_JISF|        2|\n",
      "|      Juancarfg|        2|\n",
      "|      ppoleiros|        2|\n",
      "| Maria_pilar_ga|        2|\n",
      "|      fatimar56|        2|\n",
      "|  mariarossa004|        2|\n",
      "|     mirovira75|        2|\n",
      "| lanzarotejesus|        2|\n",
      "|     ArwenPlaza|        2|\n",
      "| ALFONSOLODEIRO|        2|\n",
      "|PisandoFuerte10|        2|\n",
      "|     carrasquem|        2|\n",
      "|Migueln53227148|        2|\n",
      "|    mariasvilas|        2|\n",
      "+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OutDegree\n",
    "outDegree = (edgelist\n",
    "            .groupBy(col(\"src\").alias(\"screen_name\"))\n",
    "            .agg(\n",
    "                count(\"dst\").alias(\"outDegree\")\n",
    "            )\n",
    "            .orderBy(desc(\"outDegree\"))\n",
    "           )\n",
    "outDegree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "|    screen_name|inDegree|\n",
      "+---------------+--------+\n",
      "|           PSOE|      45|\n",
      "|   ahorapodemos|      37|\n",
      "|   CiudadanosCs|      26|\n",
      "|         vox_es|      26|\n",
      "|      populares|      25|\n",
      "|  Santi_ABASCAL|      18|\n",
      "|      JuntsXCat|       9|\n",
      "|Front_Republica|       9|\n",
      "|  AlbanoDante76|       7|\n",
      "|sanchezcastejon|       6|\n",
      "|           KRLS|       6|\n",
      "|    protestona1|       5|\n",
      "|    CastigadorY|       5|\n",
      "|   Esquerra_ERC|       5|\n",
      "| AntonioMaestre|       4|\n",
      "|         boye_g|       4|\n",
      "|     rcabrero75|       4|\n",
      "|       ivanedlm|       4|\n",
      "|   pablocasado_|       4|\n",
      "|       marubimo|       4|\n",
      "+---------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In Degree\n",
    "\n",
    "inDegree = (edgelist\n",
    "            .groupBy(col(\"dst\").alias(\"screen_name\"))\n",
    "            .agg(\n",
    "                count(\"src\").alias(\"inDegree\")\n",
    "            )\n",
    "            .orderBy(desc(\"inDegree\"))\n",
    "           )\n",
    "inDegree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef646cc68f4dc5df45a6eeb6f917fd2e",
     "grade": true,
     "grade_id": "cell-672372274353fcf0",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c47c6f9027c0c439ea46797ea0fd4ae4",
     "grade": false,
     "grade_id": "cell-49dfd94338cf09df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **Ejercicio 10**: Distribución del Grado de Salida en una Red de Retweets (*0.75 puntos*)\n",
    "\n",
    "A partir de una muestra del 1% de los tweets, con una semilla de 42 para asegurar la reproducibilidad, realiza un análisis básico de la red de retweets. Tu objetivo es calcular y mostrar la distribución de grados de los usuarios en la red de retweets.\n",
    "\n",
    "Para ello, sigue estos pasos:\n",
    "\n",
    "- Crea una tabla de Edgelist: Define una tabla `edgelist` que contenga las relaciones de retweet entre usuarios, donde cada fila representa un retweet realizado de un usuario a otro.\n",
    "\n",
    "- Calcula el Grado de Salida (Out-Degree): Determina cuántos retweets ha realizado cada usuario (es decir, el número de usuarios a los que cada usuario ha retweeteado). Llama a esta variable `outDegree`.\n",
    "\n",
    "- Obtén la Distribución de Grado de Salida: Crea una tabla `outDegree_distribution` que muestre cuántos usuarios tienen un determinado número de retweets realizados. Ordena los resultados por el grado de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d21925c6aa54dde0a30455671053808d",
     "grade": false,
     "grade_id": "cell-05526ad59455d739",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|outDegree|user_count|\n",
      "+---------+----------+\n",
      "|        1|       459|\n",
      "|        2|        26|\n",
      "|        3|         2|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "outDegree_distribution = (outDegree\n",
    "                          .groupBy(\"outDegree\")  # Agrupar por el valor del grado de salida\n",
    "                          .agg(\n",
    "                              count(\"screen_name\").alias(\"user_count\")  # Contar cuántos usuarios tienen ese grado de salida\n",
    "                          )\n",
    "                          .orderBy(\"outDegree\")  # Ordenar por el grado de salida en orden ascendente\n",
    "                         )\n",
    "outDegree_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5aa42adf43566830a8648da1a7872c0f",
     "grade": true,
     "grade_id": "cell-7e1c6a02603e3007",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "hidden"
    ]
   },
   "outputs": [],
   "source": [
    "# DO NOT USE THIS CELL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
